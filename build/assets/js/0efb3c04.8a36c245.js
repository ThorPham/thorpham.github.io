"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4106],{3905:function(n,e,t){t.d(e,{Zo:function(){return s},kt:function(){return A}});var i=t(7294);function a(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}function r(n,e){var t=Object.keys(n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(n);e&&(i=i.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),t.push.apply(t,i)}return t}function o(n){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?r(Object(t),!0).forEach((function(e){a(n,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(t,e))}))}return n}function c(n,e){if(null==n)return{};var t,i,a=function(n,e){if(null==n)return{};var t,i,a={},r=Object.keys(n);for(i=0;i<r.length;i++)t=r[i],e.indexOf(t)>=0||(a[t]=n[t]);return a}(n,e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(n);for(i=0;i<r.length;i++)t=r[i],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(n,t)&&(a[t]=n[t])}return a}var l=i.createContext({}),h=function(n){var e=i.useContext(l),t=e;return n&&(t="function"==typeof n?n(e):o(o({},e),n)),t},s=function(n){var e=h(n.components);return i.createElement(l.Provider,{value:e},n.children)},d={inlineCode:"code",wrapper:function(n){var e=n.children;return i.createElement(i.Fragment,{},e)}},p=i.forwardRef((function(n,e){var t=n.components,a=n.mdxType,r=n.originalType,l=n.parentName,s=c(n,["components","mdxType","originalType","parentName"]),p=h(t),A=a,g=p["".concat(l,".").concat(A)]||p[A]||d[A]||r;return t?i.createElement(g,o(o({ref:e},s),{},{components:t})):i.createElement(g,o({ref:e},s))}));function A(n,e){var t=arguments,a=e&&e.mdxType;if("string"==typeof n||a){var r=t.length,o=new Array(r);o[0]=p;var c={};for(var l in e)hasOwnProperty.call(e,l)&&(c[l]=e[l]);c.originalType=n,c.mdxType="string"==typeof n?n:a,o[1]=c;for(var h=2;h<r;h++)o[h]=t[h];return i.createElement.apply(null,o)}return i.createElement.apply(null,t)}p.displayName="MDXCreateElement"},8631:function(n,e,t){t.r(e),t.d(e,{assets:function(){return s},contentTitle:function(){return l},default:function(){return A},frontMatter:function(){return c},metadata:function(){return h},toc:function(){return d}});var i=t(7462),a=t(3366),r=(t(7294),t(3905)),o=["components"],c={slug:"Nh\u1eadn-di\u1ec7n-pedestrian-v\u1edbi-window-search",title:"Nh\u1eadn di\u1ec7n pedestrian v\u1edbi window search",authors:"thorpham",tags:["opencv","python","computer vision"]},l=void 0,h={permalink:"/blog/Nh\u1eadn-di\u1ec7n-pedestrian-v\u1edbi-window-search",editUrl:"https://github.com/ThorPham/blog/2018-4-11-Nh\u1eadn-di\u1ec7n -pedestrian-v\u1edbi-window-search/index.mdx",source:"@site/blog/2018-4-11-Nh\u1eadn-di\u1ec7n -pedestrian-v\u1edbi-window-search/index.mdx",title:"Nh\u1eadn di\u1ec7n pedestrian v\u1edbi window search",description:"Object regconite bao g\u1ed3m 2 ph\u1ea7n vi\u1ec7c \u0111\xf3 l\xe0 object classifier v\xe0  object detection. Hi\u1ec3u m\u1ed9t c\xe1ch \u0111\u01a1n gi\u1ea3n \u0111\xf3 l\xe0 n\u1ebfu ch\xfang ta mu\u1ed1n m\xe1y t\xednh nh\u1eadn d\u1ea1ng \u0111\u01b0\u1ee3c con m\xe8o hay con ch\xf3 th\xec tr\u01b0\u1edbc ti\xean n\xf3 s\u1ebd ph\u1ea3i detecter \u0111\u1ed1i t\u01b0\u1ee3ng \u0111\xf3 tr\xean image v\xe0 sau \u0111\xf3 xem \u0111\u1ed1i t\u01b0\u1ee3ng \u0111\xf3 l\xe0 c\xe1i g\xec b\u1eb1ng c\xe1ch classifier .V\u1edbi s\u1ef1 ph\xe1t tri\u1ec3n c\u1ee7a deep learning nh\u01b0 hi\u1ec7n nay \u0111\xe3 c\xf3 r\u1ea5t nhi\u1ec1u thu\u1eadt to\xe1n gi\xfap ta gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 n\xe0y nh\u01b0 R-CNN,Fast or Faster R-CNN,YOLO hay SSD v\u1edbi t\u1ed1c \u0111\u1ed9 x\u1eed l\xfd nhanh v\xe0 \u0111\u1ed9 ch\xednh x\xe1c cao. Tuy v\u1eady nh\u1eefng c\xe1ch truy\u1ec1n th\u1ed1ng v\u1eabn l\xe0 s\u1ef1 l\u1ef1a chon t\u1ed1t khi m\xe0 ch\xfang ta c\xf3 \xedt d\u1eef li\u1ec7u v\xe0 mu\u1ed1n build m\u1ed9t model n\xe0o \u0111\xf3 \u0111\u01a1n gi\u1ea3n h\u01a1n nh\u1eefng c\xe1i ph\u1ee9c t\u1ea1p h\u01a1n nh\u01b0 deep learning. Trong b\xe0i n\xe0y ch\xfang ta s\u1ebd nh\u1eadn di\u1ec7n pedestrian b\u1eb1ng ph\u01b0\u01a1ng ph\xe1p c\u1ed5 \u0111i\u1ec3n trong computer vision v\xe0 sau \u0111\xf3 b\u1ea1n c\xf3 th\u1ec3 t\u1ef1 build m\u1ed9t model custom n\xe0o \u0111\xf3 theo \xfd c\u1ee7a b\u1ea1n .Thu\u1eadt to\xe1n s\u1eed d\u1ee5ng trong b\xe0i l\xe0 HOG + SVM + Window search.",date:"2018-04-11T00:00:00.000Z",formattedDate:"April 11, 2018",tags:[{label:"opencv",permalink:"/blog/tags/opencv"},{label:"python",permalink:"/blog/tags/python"},{label:"computer vision",permalink:"/blog/tags/computer-vision"}],readingTime:7.53,truncated:!0,authors:[{name:"Thorpham",title:"Deep learning enthusiast",url:"https://github.com/ThorPham",imageURL:"https://github.com/ThorPham.png",key:"thorpham"}],frontMatter:{slug:"Nh\u1eadn-di\u1ec7n-pedestrian-v\u1edbi-window-search",title:"Nh\u1eadn di\u1ec7n pedestrian v\u1edbi window search",authors:"thorpham",tags:["opencv","python","computer vision"]},prevItem:{title:"T\xecm hi\u1ec3u regression trong object detection",permalink:"/blog/T\xecm-hi\u1ec3u-regression-trong-object-detection"},nextItem:{title:"T\xecm hi\u1ec3u v\u1ec1 Word2Vec",permalink:"/blog/T\xecm-hi\u1ec3u-v\u1ec1-Word2Vec"}},s={authorsImageUrls:[void 0]},d=[{value:"Giai \u0111o\u1ea1n 1 classifier",id:"giai-\u0111o\u1ea1n-1-classifier",level:2},{value:"1. Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u",id:"1-chu\u1ea9n-b\u1ecb-d\u1eef-li\u1ec7u",level:3},{value:"2. Tr\xedch ch\u1ecdn \u0111\u1eb7c tr\u01b0ng",id:"2-tr\xedch-ch\u1ecdn-\u0111\u1eb7c-tr\u01b0ng",level:3},{value:"3. Build model",id:"3-build-model",level:3},{value:"4. \u0110\xe1nh gi\xe1 v\xe0 c\u1ea3i thi\u1ec7n model",id:"4-\u0111\xe1nh-gi\xe1-v\xe0-c\u1ea3i-thi\u1ec7n-model",level:3},{value:"Giai \u0111o\u1ea1n 2  Detecter",id:"giai-\u0111o\u1ea1n-2--detecter",level:2},{value:"1. X\xe2y d\u1ef1ng sliding window",id:"1-x\xe2y-d\u1ef1ng-sliding-window",level:3},{value:"2. X\xe2y d\u1ef1ng NMS(non-maxinum-suppression)",id:"2-x\xe2y-d\u1ef1ng-nmsnon-maxinum-suppression",level:3},{value:"3. Detecter",id:"3-detecter",level:3},{value:"K\u1ebft lu\u1eadn :",id:"k\u1ebft-lu\u1eadn-",level:2}],p={toc:d};function A(n){var e=n.components,c=(0,a.Z)(n,o);return(0,r.kt)("wrapper",(0,i.Z)({},p,c,{components:e,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Object regconite bao g\u1ed3m 2 ph\u1ea7n vi\u1ec7c \u0111\xf3 l\xe0 object classifier v\xe0  object detection. Hi\u1ec3u m\u1ed9t c\xe1ch \u0111\u01a1n gi\u1ea3n \u0111\xf3 l\xe0 n\u1ebfu ch\xfang ta mu\u1ed1n m\xe1y t\xednh nh\u1eadn d\u1ea1ng \u0111\u01b0\u1ee3c con m\xe8o hay con ch\xf3 th\xec tr\u01b0\u1edbc ti\xean n\xf3 s\u1ebd ph\u1ea3i detecter \u0111\u1ed1i t\u01b0\u1ee3ng \u0111\xf3 tr\xean image v\xe0 sau \u0111\xf3 xem \u0111\u1ed1i t\u01b0\u1ee3ng \u0111\xf3 l\xe0 c\xe1i g\xec b\u1eb1ng c\xe1ch classifier .V\u1edbi s\u1ef1 ph\xe1t tri\u1ec3n c\u1ee7a deep learning nh\u01b0 hi\u1ec7n nay \u0111\xe3 c\xf3 r\u1ea5t nhi\u1ec1u thu\u1eadt to\xe1n gi\xfap ta gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 n\xe0y nh\u01b0 R-CNN,Fast or Faster R-CNN,YOLO hay SSD v\u1edbi t\u1ed1c \u0111\u1ed9 x\u1eed l\xfd nhanh v\xe0 \u0111\u1ed9 ch\xednh x\xe1c cao. Tuy v\u1eady nh\u1eefng c\xe1ch truy\u1ec1n th\u1ed1ng v\u1eabn l\xe0 s\u1ef1 l\u1ef1a chon t\u1ed1t khi m\xe0 ch\xfang ta c\xf3 \xedt d\u1eef li\u1ec7u v\xe0 mu\u1ed1n build m\u1ed9t model n\xe0o \u0111\xf3 \u0111\u01a1n gi\u1ea3n h\u01a1n nh\u1eefng c\xe1i ph\u1ee9c t\u1ea1p h\u01a1n nh\u01b0 deep learning. Trong b\xe0i n\xe0y ch\xfang ta s\u1ebd nh\u1eadn di\u1ec7n pedestrian b\u1eb1ng ph\u01b0\u01a1ng ph\xe1p c\u1ed5 \u0111i\u1ec3n trong computer vision v\xe0 sau \u0111\xf3 b\u1ea1n c\xf3 th\u1ec3 t\u1ef1 build m\u1ed9t model custom n\xe0o \u0111\xf3 theo \xfd c\u1ee7a b\u1ea1n .Thu\u1eadt to\xe1n s\u1eed d\u1ee5ng trong b\xe0i l\xe0 HOG + SVM + Window search.")),(0,r.kt)("p",null,"C\xe1ch b\u01b0\u1edbc th\u1ef1c hi\u1ec7n ta chia l\xe0m 2 giai \u0111o\u1ea1n t\u01b0\u01a1ng \u1ee9ng v\u1edbi classifier v\xe0 detecter :"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Giai \u0111o\u1ea1n 1 classifier")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"1. Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u\n2. Tr\xedch ch\u1ecdn \u0111\u1eb7c tr\u01b0ng\n3. Build model\n4. \u0110\xe1nh gi\xe1 v\xe0 c\u1ea3i thi\u1ec7n model\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Giai \u0111o\u1ea1n 2  Detection")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"1. X\xe2y d\u1ef1ng sliding window\n2. X\xe2y d\u1ef1ng NMS(non-maxinum-suppression)\n3. Detecter\n")),(0,r.kt)("h2",{id:"giai-\u0111o\u1ea1n-1-classifier"},"Giai \u0111o\u1ea1n 1 classifier"),(0,r.kt)("h3",{id:"1-chu\u1ea9n-b\u1ecb-d\u1eef-li\u1ec7u"},"1. Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u"),(0,r.kt)("p",null,"D\u1eef li\u1ec7u ch\xfang ta c\u1ea7n chu\u1ea9n b\u1ecb g\u1ed3m 2 ph\u1ea7n . M\u1ed9t l\xe0 positive sample ( g\u1ecdi t\u1eaft l\xe0 pos) l\xe0 data pedestrian v\xe0 ch\xfang ta g\u1eafn label cho n\xf3 l\xe0 1. Th\u1ee9 hai l\xe0 negative sample (Neg) l\xe0 d\u1eef li\u1ec7u kh\xf4ng ch\u1ee9a pedestrian b\u1ea1n c\xf3 th\u1ec3 l\u1ea5y nh\u01b0 background, car, house ... v\xe0 ta g\u1eafn nh\xe3n l\xe0 -1.(l\u01b0u \xfd n\u1ebfu training trong opecv th\xec nh\xe3n g\u1eafn b\u1eaft bu\u1ed9c l\xe0 1 v\xe0 -1 )."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'# image positive\npath_pos = glob.glob("./pedestrians128x64/"+"*.ppm")\nplt.subplots(figsize =(10,5))\nfor i in range(6):\n    image1 = io.imread(path_pos[i])\n    plt.subplot(1,6,i +1)\n    io.imshow(image1)\n# image negative\npath_neg = glob.glob("./pedestrians_neg/"+"*.jpg")\n')),(0,r.kt)("p",null,"D\u1eef li\u1ec7u c\u1ee7a ta g\u1ed3m c\xf3 924 image pos c\xf3 chi\u1ec1u (128, 64, 3) v\xe0 ta s\u1ebd t\u1ea1o (15x50) image neg c\xf3 chi\u1ec1u (128, 64, 3)."),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:t(9949).Z})),(0,r.kt)("h3",{id:"2-tr\xedch-ch\u1ecdn-\u0111\u1eb7c-tr\u01b0ng"},"2. Tr\xedch ch\u1ecdn \u0111\u1eb7c tr\u01b0ng"),(0,r.kt)("p",null,"Ta s\u1ebd d\xf9ng hog \u0111\u1ec3 tr\xedch ch\u1ecdn \u0111\u1eb7c tr\u01b0ng"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'def hog_feature(image):\n    feature_hog = hog(image,orientations=9,pixels_per_cell=(8,8),\n    cells_per_block=(2,2),block_norm="L2")\n    return feature_hog\n    \n#feature extraction for image pos    \nX_pos = []\ny_pos = []\nfor path in path_pos :\n    im = io.imread(path,as_grey=True)\n    im_feature = hog_feature(im)\n    X_pos.append(im_feature)\n    y_pos.append(1)\n    \n#feature extraction for image neg\nX_neg = []\ny_neg = []\nw = 64\nh = 128\nfor path in path_neg :\n    im = io.imread(path,as_grey=True)\n    for j in range(15):\n        x = np.random.randint(0,im.shape[1]-w)\n        y = np.random.randint(0,im.shape[0]-h)\n        im_crop = im[y:y+h,x:x+w]\n        im_feature = hog_feature(im_crop)\n        X_neg.append(im_feature)\n        y_neg.append(-1)\n        \n')),(0,r.kt)("p",null,"\u0110\u1ea7u ti\xean ta \u0111\u1ecbnh ngh\u0129a 1 function t\xednh hog g\u1ed3m c\xe1c tham s\u1ed1 ",(0,r.kt)("inlineCode",{parentName:"p"},'orientations=9,pixels_per_cell=(8,8),cells_per_block=(2,2),block_norm="L2"'),"\nSau \u0111\xf3 t\xednh hog tr\xean pos v\xe0 neg sample\nCu\u1ed1i c\xf9ng ta stack pos v\xe0 neg l\u1ea1i \u0111\u1ec3 chu\u1ea9n b\u1ecb training"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"X_pos = np.array(X_pos)\nX_neg = np.array(X_neg)\nX_train = np.concatenate((X_pos,X_neg))\ny_pos = np.array(y_pos)\ny_neg = np.array(y_neg)\ny_train = np.concatenate((y_pos,y_neg))\n")),(0,r.kt)("p",null,"D\u1eef li\u1ec7u trining g\u1ed3m c\xf3 ",(0,r.kt)("inlineCode",{parentName:"p"},"X_traing")," c\xf3 shape (1674, 3780) g\u1ed3m 1674 image v\xe0 3780 feature, ",(0,r.kt)("inlineCode",{parentName:"p"},"y_training")," c\xf3 shape l\xe0 (1674,) g\u1ed3m 2 gi\xe1 tr\u1ecb 1 l\xe0 pedestrian v\xe0 -1 l\xe0 non-pedestrian"),(0,r.kt)("h3",{id:"3-build-model"},"3. Build model"),(0,r.kt)("p",null,"Ch\xfang ta s\u1ebd training model b\u1eb1ng thu\u1eadt to\xe1n svm c\xf3 trong th\u01b0 vi\u1ec7n sklearn."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"from sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report\nmodel = LinearSVC(C=0.01)\nmodel.fit(X_train,y_train)\ny_predict = model.predict(X_train)\nprint(classification_report(y_train,y_predict))\n")),(0,r.kt)("p",null,"K\u1ebft qu\u1ea3 nh\u01b0 sau :"),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:t(3928).Z})),(0,r.kt)("h3",{id:"4-\u0111\xe1nh-gi\xe1-v\xe0-c\u1ea3i-thi\u1ec7n-model"},"4. \u0110\xe1nh gi\xe1 v\xe0 c\u1ea3i thi\u1ec7n model"),(0,r.kt)("p",null,"Amazing! k\u1ebft qu\u1ea3 accuracy = 100% . Qu\xe1 cao ph\u1ea3i ko. Nh\u01b0ng \u0111\u1eebng m\u1eebng v\u1ed9i v\xec data c\u1ee7a ch\xfang ta r\u1ea5t nh\u1ecf v\xe0 ta d\xf9ng to\xe0n b\u1ed9 data v\xe0o training m\xe0 ko chia ra data testing n\xean r\u1ea5t c\xf3 th\u1ec3 b\u1ecb overfiting. Khi \u0111\xf3 model \u0111\u01b0a v\xe0o ho\u1ea1t \u0111\u1ed9ng s\u1ebd predict kh\xf4ng t\u1ed1t. \u0110\u1ec3 tr\xe1nh \u0111i\u1ec1u n\xe0y\nta c\xf3 th\u1ec3 thay \u0111\u1ed5i threshold  ( v\xec khi predict tr\xean image l\u1edbn s\u1ebd c\xf3 r\u1ea5t nhi\u1ec1u non-pedestrian h\u01a1n l\xe0 pedestrian).\u1ede trong sklearn m\u1eb7c \u0111\u1ecbnh ",(0,r.kt)("inlineCode",{parentName:"p"},"model.prediction")," l\xe0 0.5 n\xean ta kh\xf4ng th\u1ec3 n\xe0o thay \u0111\u1ed5i \u0111\u01b0\u1ee3c n\xf3. Ta ch\u1ec9 c\xf3 th\u1ec3 thay \u0111\u1ed5i qua ",(0,r.kt)("inlineCode",{parentName:"p"},"decision_function")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'from sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import cross_val_predict\ny_scores = cross_val_predict(model, X_train, y_train, cv=3,\n                             method="decision_function")[:,1]\nprecisions, recalls, thresholds = precision_recall_curve(y_train, y_scores)\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], "b--", label="Precision")\n    plt.plot(thresholds, recalls[:-1], "g-", label="Recall")\n    plt.xlabel("Threshold")\n    plt.legend(loc="center left")\n    plt.ylim([0, 1])\n\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n')),(0,r.kt)("p",null,"Ta th\u1ea5y khi threshold = 0 recall = 1 , khi recall = 0.8 th\xec threshold t\u0103ng l\xean 0.7"),(0,r.kt)("h2",{id:"giai-\u0111o\u1ea1n-2--detecter"},"Giai \u0111o\u1ea1n 2  Detecter"),(0,r.kt)("p",null,"B\xe2y gi\u1edd ta s\u1ebd detecter pedestrian tr\xean \u1ea3nh l\u1edbn."),(0,r.kt)("h3",{id:"1-x\xe2y-d\u1ef1ng-sliding-window"},"1. X\xe2y d\u1ef1ng sliding window"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"def sliding_window(image,window_size,step_size):\n    for y in range(0,image.shape[0]-window_size[1],step_size[1]):\n        for x in range(0,image.shape[1]-window_size[0],step_size[0]):\n            roi = image[y:y+window_size[1],x:x+window_size[0]]\n            yield (x,y,roi)\n")),(0,r.kt)("p",null,"Function ",(0,r.kt)("inlineCode",{parentName:"p"},"sliding_window")," c\xf3 3 para : 1 l\xe0 ",(0,r.kt)("inlineCode",{parentName:"p"},"image")," (l\xe0 1 \u1ea3nh x\xe1m), hai l\xe0 ",(0,r.kt)("inlineCode",{parentName:"p"},"window_size")," c\xf3 chi\u1ec1u (mxn) l\xe0 k\xedch th\u01b0\u1edbc window tr\xean image, cu\u1ed1i c\xf9ng l\xe0 ",(0,r.kt)("inlineCode",{parentName:"p"},"step_size")," c\xf3 chi\u1ec1u (w,h) l\xe0 stride theo ox,oy tr\xean image.Gi\xe1 tr\u1ecb tr\u1ea3 v\u1ec1 l\xe0 v\u1ecb tr\xed (x,y) t\u01b0\u01a1ng \u1ee9ng l\xe0 (top-left) v\xe0 roi l\xe0 slide window t\u01b0\u01a1ng \u1ee9ng."),(0,r.kt)("h3",{id:"2-x\xe2y-d\u1ef1ng-nmsnon-maxinum-suppression"},"2. X\xe2y d\u1ef1ng NMS(non-maxinum-suppression)"),(0,r.kt)("p",null,"Ta ch\u1ec9 gi\u1eef l\u1ea1i 1 window tr\xean 1 object m\xe0 th\xf4i n\xean ta s\u1ebd d\xf9ng NMS \u0111\u1ec3 lo\u1ea1i b\u1ecf c\xe1c window c\xf2n l\u1ea1i, gi\u1eef l\u1ea1i window t\u1ed1i \u01b0u nh\u1ea5t.\u0110\u1ea7u ti\xean ta c\u1ea7n t\xednh area overlap gi\u1eefa 2 window."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"def overlaping_area(detection_1,detection_2):\n    #detection_1,detection_2 format [x_left_top,y_left_top,score,width,height]\n    x_1 = detection_1[0]\n    y_1 = detection_1[1]\n    x_w_1 = detection_1[0] + detection_1[3]\n    y_h_1 = detection_1[1] + detection_1[4]\n    \n    x_2 = detection_2[0]\n    y_2 = detection_2[1]\n    x_w_2 = detection_2[0] + detection_2[3]\n    y_h_2 = detection_2[1] + detection_2[4]\n    #t\xednh overlap theo ox,oy .N\u1ebfu ko giao nhau tr\u1ea3 v\u1ec1 0\n    overlap_x = max(0,min(x_w_1,x_w_2) - max(x_1,x_2))\n    overlap_y = max(0,min(y_h_1,y_h_2) - max(y_1,y_2))\n    #t\xednh area overlap\n    overlap_area = overlap_x*overlap_y\n    #t\xednh total area h\u1ee3p c\u1ee7a 2 detection\n    total_area = detection_1[3]*detection_1[4] + detection_2[3]*detection_2[4] - overlap_area\n    \n    return overlap_area/float(total_area)\n")),(0,r.kt)("p",null,"\u0110\xe2y l\xe0 b\xe0i to\xe1n t\xecm intersection gi\u1eefa 2 rectangle b\u1ea1n c\xf3 th\u1ec3 search google xem c\xe1i gi\u1ea3i quy\u1ebft. H\xe0m overlaping_area s\u1ebd tr\u1ea3 v\u1ec1 t\u1ec9 l\u1ec7 overlap tr\xean t\u1ed5ng area gi\u1eefa 2 rectangle.\nTi\u1ebfp theo ch\xfang ta x\xe2y d\u1ef1ng l\xe0m NMS ."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"def nms(detections,threshold =0.4):\n    # decections format [x_left_top,y_left_top,score,width,height]\n    # n\u1ebfu area overlap l\u1edbn h\u01a1n threshold th\xec s\u1ebd remove detection n\xe0o c\xf3 score nh\u1ecf h\u01a1n\n    if len(detections)==0:\n        return []\n    #sort detection theo score\n    detections = sorted(detections,key = lambda detections : detections[2],reverse = True)\n    #create new detection\n    new_detections = []\n    new_detections.append(detections[0])\n    del detections[0]\n    for index,detection in enumerate(detections):\n        for new_detection in new_detections:\n            if overlaping_area(detection,new_detection)> threshold : #compare areaoverlap v\u1edbi threshold\n                del detections[index]\n                break\n        else :\n            new_detections.append(detection)\n            del detections[index]\n    return new_detections\n")),(0,r.kt)("p",null,"\xdd t\u01b0\u1edfng l\xe0 ch\xfang ta s\u1ebd sort c\xe1c detection theo score( decision_function) theo th\u1ee9 t\u1ef1 gi\u1ea3m d\u1ea7n. Sau \u0111\xf3 so s\xe1nh c\xe1c detection v\u1edbi nhau, n\u1ebfu area overlap h\u01a1n threshold th\xec ta s\u1ebd gi\u1eef l\u1ea1i detection n\xe0o c\xf3 score l\u1edbn h\u01a1n."),(0,r.kt)("h3",{id:"3-detecter"},"3. Detecter"),(0,r.kt)("p",null,"\u0110\u1ebfn \u0111\xe2y ta s\u1ebd stack c\xe1c function \u0111\xe3 t\u1ea1o l\u1ea1i v\u1edbi nhau th\xe0nh m\u1ed9t kh\u1ed1i \u0111\u1ec3 detection tr\xean \u1ea3nh l\u1edbn."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'image = cv2.imread("pedestrian.jpg")\nimage_test = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n\nwindow_size = (64,128)\nstep_size = (10,10)\ndetections = []\ndownscale=1.5\nscale = 0\nfor image_scale in pyramid_gaussian(image_test,downscale=2):\n    scale += 1\n    if image_scale.shape[0] < window_size[1] or image_scale.shape[1] < window_size[0]:\n        break\n    for (x,y,roi) in sliding_window(image_scale,window_size,step_size):\n        feature = hog_feature(roi)\n        predict = model.predict(feature.reshape((-1,3780)))\n        score = model.decision_function(feature.reshape((-1,3780)))\n        if (predict == 1) and (score>0.5):\n            detections.append([x,y,np.round(score,4),window_size[0],window_size[1]])\ndetections = nms(detections,0.5)\nfor (x,y,_,w,h) in detections :\n    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),3)\ncv2.imshow("roi",image)\ncv2.waitKey()\ncv2.destroyAllWindows()\n')),(0,r.kt)("p",null,"Gi\u1ea3i th\xedch code 1 t\xed:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"V\xec window size c\u1ed1 \u0111\u1ecbnh m\xe0 object m\u1ed7i image s\u1ebd c\xf3 k\xedch th\u01b0\u1edbc kh\xe1c nhau n\xean ta s\u1ebd d\xf9ng 1 function t\u1ea1o image pyramid, trong b\xe0i ta s\u1ebd s\u1eed d\u1ee5ng pyramid_gaussian v\u1edbi downscale = 2 , c\xf3 ngh\u0129a sau m\u1ed7i l\u1ea7n ch\u1ea1y image s\u1ebd gi\u1ea3m xu\u1ed1ng 1 n\u1eefa"),(0,r.kt)("li",{parentName:"ul"},"\u0110\u1ec3 gi\u1ea3m b\u1edbt nhi\u1ec5u ta s\u1ebd s\u1eed d\u1ee5ng score > 0.25"),(0,r.kt)("li",{parentName:"ul"},"\u1ede \u0111\xe2y c\xf3 m\u1ed9t nh\u01b0\u1ee3c \u0111i\u1ec3m l\xe0 khi image downscale th\xec bounding box c\u1ee7a ta s\u1ebd kh\xf4ng \u0111\u1ed5i l\xe0m cho object kh\xf4ng \u0111\u01b0\u1ee3c bao to\xe0n b\u1ed9 b\u1edfi bounding box m\xecnh \u0111\u1ecbnh s\u1ebd t\u0103ng k\xedch th\u01b0\u1edbc bounding box b\u1eb1ng c\xe1ch nh\xe2n cho n\xf3 1 t\u1ef7 l\u1ec7 b\u1eb1ng (downscale^scale) nh\u01b0ng k\u1ebft qu\u1ea3 l\xe0 bouding box qu\xe1 to. Hi\u1ec7n gi\u1edd m\xecnh ch\u01b0a t\xecm ra c\xe1ch x\u1eed l\xfd. C\xf3 th\u1ec3 xem minh h\u1ecda \u1edf h\xecnh d\u01b0\u1edbi.")),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:t(8113).Z})),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:t(7170).Z})),(0,r.kt)("h2",{id:"k\u1ebft-lu\u1eadn-"},"K\u1ebft lu\u1eadn :"),(0,r.kt)("p",null,"Thu\u1eadt to\xe1n build model nhanh tuy nhi\xean c\xf3 m\u1ed9t nh\u01b0\u1ee3c \u0111i\u1ec3m l\xe0 predict tr\xean camera r\u1ea5t delay b\u1edfi v\xec ta s\u1eed d\u1ee5ng window search n\xean predict r\u1ea5t nhi\u1ec1u image d\u1eabn \u0111\u1ebfn t\u1ed1n th\u1eddi gian r\u1ea5t nhi\u1ec1u. Ng\xe0y nay ng\u01b0\u1eddi ta \u0111\xe3 gi\u1ea3i quy\u1ebft \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 n\xe0y b\u1eb1ng c\xe1ch s\u1eed d\u1ee5ng selective search c\xf3 ngh\u0129a l\xe0 ko search windown to\xe0n image n\u1eefa m\xe0 search c\xf3 ch\u1ecdn l\u1ecdc, nh\u1eefng region proposal m\xe0 c\xf3 nhi\u1ec1u kh\u1eb3n n\u0103ng c\xf3 object nh\u1ea5t \u0111i\u1ec3n h\xecnh l\xe0 thu\u1eadt to\xe1n R-CNN."),(0,r.kt)("p",null,"Tham Kh\u1ea3o : "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"http://hanzratech.in/"},"http://hanzratech.in/")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://pyimagesearch.com"},"https://pyimagesearch.com")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://learnopencv.com"},"https://learnopencv.com"))))}A.isMDXComponent=!0},3928:function(n,e){e.Z="data:image/jpeg;base64,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"},8113:function(n,e,t){e.Z=t.p+"assets/images/final1-d5aca5d2e472d79d3decd2645c1eb385.jpg"},7170:function(n,e,t){e.Z=t.p+"assets/images/final2-7425dfefbe9788bbd8aa64fb81783a4c.jpg"},9949:function(n,e,t){e.Z=t.p+"assets/images/pedestian1-a24ec58650d8d86276a1e9d77b9875be.jpg"}}]);