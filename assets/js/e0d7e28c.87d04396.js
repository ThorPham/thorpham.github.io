"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1909],{3905:function(n,t,e){e.d(t,{Zo:function(){return s},kt:function(){return u}});var a=e(7294);function i(n,t,e){return t in n?Object.defineProperty(n,t,{value:e,enumerable:!0,configurable:!0,writable:!0}):n[t]=e,n}function r(n,t){var e=Object.keys(n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(n);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(n,t).enumerable}))),e.push.apply(e,a)}return e}function l(n){for(var t=1;t<arguments.length;t++){var e=null!=arguments[t]?arguments[t]:{};t%2?r(Object(e),!0).forEach((function(t){i(n,t,e[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(e)):r(Object(e)).forEach((function(t){Object.defineProperty(n,t,Object.getOwnPropertyDescriptor(e,t))}))}return n}function m(n,t){if(null==n)return{};var e,a,i=function(n,t){if(null==n)return{};var e,a,i={},r=Object.keys(n);for(a=0;a<r.length;a++)e=r[a],t.indexOf(e)>=0||(i[e]=n[e]);return i}(n,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(n);for(a=0;a<r.length;a++)e=r[a],t.indexOf(e)>=0||Object.prototype.propertyIsEnumerable.call(n,e)&&(i[e]=n[e])}return i}var o=a.createContext({}),c=function(n){var t=a.useContext(o),e=t;return n&&(e="function"==typeof n?n(t):l(l({},t),n)),e},s=function(n){var t=c(n.components);return a.createElement(o.Provider,{value:t},n.children)},p={inlineCode:"code",wrapper:function(n){var t=n.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(n,t){var e=n.components,i=n.mdxType,r=n.originalType,o=n.parentName,s=m(n,["components","mdxType","originalType","parentName"]),h=c(e),u=i,g=h["".concat(o,".").concat(u)]||h[u]||p[u]||r;return e?a.createElement(g,l(l({ref:t},s),{},{components:e})):a.createElement(g,l({ref:t},s))}));function u(n,t){var e=arguments,i=t&&t.mdxType;if("string"==typeof n||i){var r=e.length,l=new Array(r);l[0]=h;var m={};for(var o in t)hasOwnProperty.call(t,o)&&(m[o]=t[o]);m.originalType=n,m.mdxType="string"==typeof n?n:i,l[1]=m;for(var c=2;c<r;c++)l[c]=e[c];return a.createElement.apply(null,l)}return a.createElement.apply(null,e)}h.displayName="MDXCreateElement"},5754:function(n,t,e){e.r(t),e.d(t,{assets:function(){return s},contentTitle:function(){return o},default:function(){return u},frontMatter:function(){return m},metadata:function(){return c},toc:function(){return p}});var a=e(7462),i=e(3366),r=(e(7294),e(3905)),l=["components"],m={slug:"Qu\xe1-tr\xecnh-ph\xe1t-tri\u1ec3n-c\u1ee7a-CNN-t\u1eeb-LeNet-\u0111\u1ebfn-DenseNet",title:"Qu\xe1 tr\xecnh ph\xe1t tri\u1ec3n c\u1ee7a CNN t\u1eeb LeNet \u0111\u1ebfn DenseNet.",authors:"thorpham",tags:["Deep learning","CNN"]},o=void 0,c={permalink:"/blog/Qu\xe1-tr\xecnh-ph\xe1t-tri\u1ec3n-c\u1ee7a-CNN-t\u1eeb-LeNet-\u0111\u1ebfn-DenseNet",editUrl:"https://github.com/ThorPham/blog/2018-10-8-Qu\xe1-tr\xecnh-ph\xe1t-tri\u1ec3n-c\u1ee7a-CNN-t\u1eeb-LeNet-\u0111\u1ebfn-DenseNet/index.md",source:"@site/blog/2018-10-8-Qu\xe1-tr\xecnh-ph\xe1t-tri\u1ec3n-c\u1ee7a-CNN-t\u1eeb-LeNet-\u0111\u1ebfn-DenseNet/index.md",title:"Qu\xe1 tr\xecnh ph\xe1t tri\u1ec3n c\u1ee7a CNN t\u1eeb LeNet \u0111\u1ebfn DenseNet.",description:"Convolutional neural network l\xe0 m\u1ed9t m\u1ea1ng neural \u0111\u01b0\u1ee3c \u1ee9ng d\u1ee5ng r\u1ea5t nhi\u1ec1u trong deep learning trong computer vision cho classifier v\xe0 localizer . T\u1eeb m\u1ea1ng CNN c\u01a1 b\u1ea3n ng\u01b0\u1eddi ta c\xf3 th\u1ec3 t\u1ea1o ra r\u1ea5t nhi\u1ec1u architect kh\xe1c nhau, t\u1eeb nh\u1eefng m\u1ea1ng neural c\u01a1 b\u1ea3n 1 \u0111\u1ebfn 2 layer \u0111\u1ebfn 100 layer. \u0110\xe3 bao gi\u1edd b\u1ea1n t\u1ef1 h\u1ecfi n\xean s\u1eed d\u1ee5ng bao nhi\xeau layer, n\xean k\u1ebft h\u1ee3p conv v\u1edbi maxpooling th\u1ebf n\xe0o? conv-maxpooling hay conv-conv-maxplooling ? hay n\xean s\u1eed d\u1ee5ng kernel 3x3 hay 5x5 th\u1eadm ch\xed 7x7 \u0111i\u1ec3m kh\xe1c bi\u1ec7t l\xe0 g\xec ? L\xe0m g\xec khi model b\u1ecb vanishing/exploding gradient, hay t\u1ea1i sao thi th\xeam nhi\u1ec1u layer h\u01a1n th\xec theo l\xfd thuy\u1ebft accuarcy ph\u1ea3i cao h\u01a1n so v\u1edbi shallow model, nh\u01b0ng th\u1ef1c t\u1ebf l\u1ea1i kh\xf4ng ph\u1ea3i accuarcy kh\xf4ng t\u0103ng th\u1eadm ch\xed l\xe0 gi\u1ea3m \u0111\xf3 c\xf3 ph\u1ea3i nguy\xean nh\xe2n do overfitting .Trong b\xe0i vi\u1ebft n\xe0y ta s\u1ebd t\xecm hi\u1ec3u c\xe1c architure n\u1ed5i ti\u1ebfng \u0111\u1ec3 xem c\u1ea5u tr\xfac c\u1ee7a n\xf3 nh\u01b0 th\u1ebf n\xe0o, c\xe1c \xfd t\u01b0\u1edfng v\u1ec1 CNN m\u1edbi nh\u1ea5t hi\u1ec7n nay  t\u1eeb \u0111\xf3 ta c\xf3 th\u1ec3 tr\u1ea3 l\u1eddi \u0111\u01b0\u1ee3c m\u1ea5y c\xe2u h\u1ecfi tr\xean",date:"2018-10-08T00:00:00.000Z",formattedDate:"October 8, 2018",tags:[{label:"Deep learning",permalink:"/blog/tags/deep-learning"},{label:"CNN",permalink:"/blog/tags/cnn"}],readingTime:15.165,truncated:!0,authors:[{name:"Thorpham",title:"Deep learning enthusiast",url:"https://github.com/ThorPham",imageURL:"https://github.com/ThorPham.png",key:"thorpham"}],frontMatter:{slug:"Qu\xe1-tr\xecnh-ph\xe1t-tri\u1ec3n-c\u1ee7a-CNN-t\u1eeb-LeNet-\u0111\u1ebfn-DenseNet",title:"Qu\xe1 tr\xecnh ph\xe1t tri\u1ec3n c\u1ee7a CNN t\u1eeb LeNet \u0111\u1ebfn DenseNet.",authors:"thorpham",tags:["Deep learning","CNN"]},prevItem:{title:"H\u01b0\u1edbng ti\u1ebfp c\u1eadn Graph convolution network cho b\xe0i to\xe1n r\xfat tr\xedch th\xf4ng tin t\u1eeb h\xf3a \u0111\u01a1n",permalink:"/blog/Graph-convolution-network-cho-b\xe0i-to\xe1n-r\xfat-tr\xedch-th\xf4ng-tin"},nextItem:{title:"Object detection t\u1eeb R-CNN \u0111\u1ebfn Faster R-CNN",permalink:"/blog/Object-detection-t\u1eeb-R-CNN-\u0111\u1ebfn-Faster-R-CNN"}},s={authorsImageUrls:[void 0]},p=[{value:"1. LeNet(1998)",id:"1-lenet1998",level:2},{value:"2. Alexnet(2012)",id:"2-alexnet2012",level:2},{value:"3. ZFNet(2013)",id:"3-zfnet2013",level:2},{value:"4. VGGNet(2014).",id:"4-vggnet2014",level:2},{value:"5. GoogleNet(2014).",id:"5-googlenet2014",level:2},{value:"6. ResNets(2015).",id:"6-resnets2015",level:2},{value:"7. Densenet(2016)",id:"7-densenet2016",level:2}],h={toc:p};function u(n){var t=n.components,m=(0,i.Z)(n,l);return(0,r.kt)("wrapper",(0,a.Z)({},h,m,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Convolutional neural network l\xe0 m\u1ed9t m\u1ea1ng neural \u0111\u01b0\u1ee3c \u1ee9ng d\u1ee5ng r\u1ea5t nhi\u1ec1u trong deep learning trong computer vision cho classifier v\xe0 localizer . T\u1eeb m\u1ea1ng CNN c\u01a1 b\u1ea3n ng\u01b0\u1eddi ta c\xf3 th\u1ec3 t\u1ea1o ra r\u1ea5t nhi\u1ec1u architect kh\xe1c nhau, t\u1eeb nh\u1eefng m\u1ea1ng neural c\u01a1 b\u1ea3n 1 \u0111\u1ebfn 2 layer \u0111\u1ebfn 100 layer. \u0110\xe3 bao gi\u1edd b\u1ea1n t\u1ef1 h\u1ecfi n\xean s\u1eed d\u1ee5ng bao nhi\xeau layer, n\xean k\u1ebft h\u1ee3p conv v\u1edbi maxpooling th\u1ebf n\xe0o? conv-maxpooling hay conv-conv-maxplooling ? hay n\xean s\u1eed d\u1ee5ng kernel 3x3 hay 5x5 th\u1eadm ch\xed 7x7 \u0111i\u1ec3m kh\xe1c bi\u1ec7t l\xe0 g\xec ? L\xe0m g\xec khi model b\u1ecb vanishing/exploding gradient, hay t\u1ea1i sao thi th\xeam nhi\u1ec1u layer h\u01a1n th\xec theo l\xfd thuy\u1ebft accuarcy ph\u1ea3i cao h\u01a1n so v\u1edbi shallow model, nh\u01b0ng th\u1ef1c t\u1ebf l\u1ea1i kh\xf4ng ph\u1ea3i accuarcy kh\xf4ng t\u0103ng th\u1eadm ch\xed l\xe0 gi\u1ea3m \u0111\xf3 c\xf3 ph\u1ea3i nguy\xean nh\xe2n do overfitting .Trong b\xe0i vi\u1ebft n\xe0y ta s\u1ebd t\xecm hi\u1ec3u c\xe1c architure n\u1ed5i ti\u1ebfng \u0111\u1ec3 xem c\u1ea5u tr\xfac c\u1ee7a n\xf3 nh\u01b0 th\u1ebf n\xe0o, c\xe1c \xfd t\u01b0\u1edfng v\u1ec1 CNN m\u1edbi nh\u1ea5t hi\u1ec7n nay  t\u1eeb \u0111\xf3 ta c\xf3 th\u1ec3 tr\u1ea3 l\u1eddi \u0111\u01b0\u1ee3c m\u1ea5y c\xe2u h\u1ecfi tr\xean")),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(4502).Z})),(0,r.kt)("center",null,"H\xecnh 1. Qu\xe1 tr\xecnh ph\xe1t tri\u1ec3n c\u1ee7a CNN"),(0,r.kt)("h2",{id:"1-lenet1998"},"1. LeNet(1998)"),(0,r.kt)("p",null,"LeNet l\xe0 m\u1ed9t trong nh\u1eefng m\u1ea1ng CNN l\xe2u \u0111\u1eddi n\u1ed5i ti\u1ebfng nh\u1ea5t \u0111\u01b0\u1ee3c Yann LeCUn ph\xe1t tri\u1ec3n v\xe0o nh\u1eefng n\u0103m 1998s. C\u1ea5u tr\xfac c\u1ee7a LeNet g\u1ed3m 2 layer (Convolution + maxpooling) v\xe0 2 layer fully  connected  layer v\xe0 output l\xe0 softmax layer .  "),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(980).Z})),(0,r.kt)("center",null,"H\xecnh 2. LeNet (Source CNN c\u1ee7a Andrew Ng)"),(0,r.kt)("p",null,"Ch\xfang ta c\xf9ng t\xecm hi\u1ec3u chi ti\u1ebft architect c\u1ee7a LeNet \u0111\u1ed1i v\u1edbi d\u1eef li\u1ec7u mnist (accuracy l\xean \u0111\u1ebfn 99%) :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Input shape 28x28x3"),(0,r.kt)("li",{parentName:"ul"},"Layer 1 :",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Convolution layer 1 : Kernel 5x5x3 , stride = 1,no padding, number filter = 6 ,output = 28x28x6."),(0,r.kt)("li",{parentName:"ul"},"Maxpooling layer : pooling size 2x2,stride = 2,padding = \u201csame\u201d,output = 14x14x6."))),(0,r.kt)("li",{parentName:"ul"},"Layer 2 :",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Convolution layer 2 : kernel 5x5x6,stride = 1, no padding, number filter = 16,output = 10x10x16."),(0,r.kt)("li",{parentName:"ul"},"Maxpooling layer : pooling size = 2x2, stride = 2, padding =\u201dsame\u201d,output = 5x5x16."))),(0,r.kt)("li",{parentName:"ul"},"Flatten output = 5x5x16 = 400"),(0,r.kt)("li",{parentName:"ul"},"Fully connection 1 : output = 120"),(0,r.kt)("li",{parentName:"ul"},"Fully connection 2 : output = 84"),(0,r.kt)("li",{parentName:"ul"},"Softmax layer, output = 10 (10 digits).")),(0,r.kt)("p",null,"Nh\u01b0\u1ee3c \u0111i\u1ec3m c\u1ee7a LeNet l\xe0 m\u1ea1ng c\xf2n r\u1ea5t \u0111\u01a1n gi\u1ea3n v\xe0 s\u1eed d\u1ee5ng sigmoid (or tanh) \u1edf m\u1ed7i convolution layer m\u1ea1ng t\xednh to\xe1n r\u1ea5t ch\u1eadm."),(0,r.kt)("h2",{id:"2-alexnet2012"},"2. Alexnet(2012)"),(0,r.kt)("p",null,"AlexNet l\xe0 m\u1ed9t m\u1ea1ng CNN \u0111\xe3 d\xe0nh chi\u1ebfn th\u1eafng trong cu\u1ed9c thi ImageNet LSVRC-2012 n\u0103m 2012 v\u1edbi large margin (15.3% VS 26.2% error rates). AlexNet l\xe0 m\u1ed9t m\u1ea1ng CNN traning v\u1edbi m\u1ed9t s\u1ed1 l\u01b0\u1ee3ng parameter r\u1ea5t l\u1edbn (60 million) so v\u1edbi LeNet. M\u1ed9t s\u1ed1 \u0111\u1eb7c \u0111i\u1ec3m:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"S\u1eed d\u1ee5ng relu thay cho sigmoid(or tanh) \u0111\u1ec3 x\u1eed l\xfd v\u1edbi non-linearity. T\u0103ng t\u1ed1c \u0111\u1ed9 t\xednh to\xe1n l\xean 6 l\u1ea7n."),(0,r.kt)("li",{parentName:"ul"},"S\u1eed d\u1ee5ng dropout nh\u01b0 m\u1ed9t ph\u01b0\u01a1ng ph\xe1p regularization m\u1edbi cho CNN. Dropout kh\xf4ng nh\u1eefng gi\xfap m\xf4 h\xecnh tr\xe1nh \u0111\u01b0\u1ee3c overfitting m\xe0 c\xf2n l\xe0m gi\u1ea3m th\u1eddi gian hu\u1ea5n luy\u1ec7n m\xf4 h\xecnh "),(0,r.kt)("li",{parentName:"ul"},"Overlap pooling \u0111\u1ec3 gi\u1ea3m size c\u1ee7a network ( Traditionally pooling regions kh\xf4ng overlap)."),(0,r.kt)("li",{parentName:"ul"},"S\u1eed d\u1ee5ng local response normalization \u0111\u1ec3 chu\u1ea9n h\xf3a \u1edf m\u1ed7i layer."),(0,r.kt)("li",{parentName:"ul"},"S\u1eed d\u1ee5ng k\u1ef9 thu\u1eadt data augmentation \u0111\u1ec3 t\u1ea1o th\xeam data training b\u1eb1ng c\xe1ch translations, horizontal reflections."),(0,r.kt)("li",{parentName:"ul"},"Alexnet training v\u1edbi 90 epochs trong 5 \u0111\u1ebfn 6 ng\xe0y v\u1edbi 2 GTX 580 GPUs. S\u1eed d\u1ee5ng SGD v\u1edbi learning rate 0.01, momentum 0.9 v\xe0 weight decay 0.0005. ")),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(103).Z})),(0,r.kt)("center",null,"H\xecnh 3. AlexNet (Ngu\u1ed3n ImageNet Classification with Deep Convolutional Neural Networks)"),(0,r.kt)("p",null,"Architect c\u1ee7a Alexnet g\u1ed3m 5 convolutional layer v\xe0 3 fully  connected  layer. Activation Relu \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng sau m\u1ed7i convolution v\xe0 fully connection layer. Detail architecture v\u1edbi dataset l\xe0 imagenet size l\xe0 227x227x3 v\u1edbi 1000 class ( kh\xe1c v\u1edbi trong h\xecnh tr\xean size l\xe0 224x224). "),(0,r.kt)("p",null,"Detail Architect:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Input shape 227x227x3."),(0,r.kt)("li",{parentName:"ul"},"Layer 1 :",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Conv 1 : kernel : 11x11x3,stride = 4,no padding, number = 96,activation = relu,output = 55x55x96."),(0,r.kt)("li",{parentName:"ul"},"Maxpooling layer : pooling size = 3x3,stride = 2,padding =\u201dsame\u201d ,output = 27x27x96."),(0,r.kt)("li",{parentName:"ul"},"Normalize layer."))),(0,r.kt)("li",{parentName:"ul"},"Layer 2 :",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Conv 2 : kernel :3x3x96,stride = 1, padding = \u201csame\u201d, number filter = 256,activation = relu,output = 27x27x256."),(0,r.kt)("li",{parentName:"ul"},"Maxpooling layer : pooling size = 3x3,stride=2, padding =\u201dsame\u201d,output = 13x13x256."),(0,r.kt)("li",{parentName:"ul"},"Normalize layer."))),(0,r.kt)("li",{parentName:"ul"},"Layer 3:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Conv 3 : kernel :3x3x256, stride = 1,padding=\u201dsame\u201d, number filter = 384, activation = relu, output = 13x13x384."))),(0,r.kt)("li",{parentName:"ul"},"Layer 4:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Conv 4 : kernel : 3x3x384 , stride = 1, padding = \u201csame\u201d, number filter = 384, activation= relu, output = 13x13x384"))),(0,r.kt)("li",{parentName:"ul"},"Layer 5 :",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Conv 5 : kernel 3x3x384, stride = 1, padding = \u201csame\u201d, number filter = 256, activation = relu, output = 13x13x256."),(0,r.kt)("li",{parentName:"ul"},"Pooling layer : pooling size = 3x3,stride =2,padding =\u201dsame\u201d,output = 6x6x256."))),(0,r.kt)("li",{parentName:"ul"},"Flatten 256x6x6 = 9216"),(0,r.kt)("li",{parentName:"ul"},"Fully connection layer 1 : activation = relu , output = 4096 + dropout(0.5)."),(0,r.kt)("li",{parentName:"ul"},"Fully connection layer 2 : activation = relu , output = 4096 + dropout(0.5)."),(0,r.kt)("li",{parentName:"ul"},"Fully connection layer 3 : activation = softmax , output = 1000 (number class) ")),(0,r.kt)("h2",{id:"3-zfnet2013"},"3. ZFNet(2013)"),(0,r.kt)("p",null,"ZFNet l\xe0 m\u1ed9t m\u1ea1ng cnn th\u1eafng trong ILSVRC 2013 v\u1edbi top-5 error rate c\u1ee7a 14.8% . ZFNet c\xf3 c\u1ea5u tr\xfac r\u1ea5t gi\u1ed1ng v\u1edbi AlexNet v\u1edbi 5 layer convolution , 2 fully connected layer v\xe0 1 output softmax layer. Kh\xe1c bi\u1ec7t \u1edf ch\u1ed7 kernel size \u1edf m\u1ed7i Conv layer .M\u1ed9t s\u1ed1 \u0111\u1eb7c \u0111i\u1ec3m ch\xednh :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"T\u01b0\u01a1ng t\u1ef1 AlexNet nh\u01b0ng c\xf3 m\u1ed9t s\u1ed1 \u0111i\u1ec1u ch\u1ec9nh nh\u1ecf."),(0,r.kt)("li",{parentName:"ul"},"Alexnet training tr\xean 15m image trong khi ZF training ch\u1ec9 c\xf3 1.3m image."),(0,r.kt)("li",{parentName:"ul"},"S\u1eed d\u1ee5ng kernel 7x7 \u1edf first layer (alexnet 11x11).L\xfd do l\xe0 s\u1eed d\u1ee5ng kernel nh\u1ecf h\u01a1n \u0111\u1ec3 gi\u1eef l\u1ea1i nhi\u1ec1u th\xf4ng tin tr\xean image h\u01a1n."),(0,r.kt)("li",{parentName:"ul"},"T\u0103ng s\u1ed1 l\u01b0\u1ee3ng filter nhi\u1ec1u h\u01a1n so v\u1edbi alexnet"),(0,r.kt)("li",{parentName:"ul"},"Training tr\xean GTX 580 GPU trong 20 ng\xe0y",(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(6702).Z})))),(0,r.kt)("center",null,"H\xecnh 4. ZFNet(2013)."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Input shape 224x224x3 ."),(0,r.kt)("li",{parentName:"ul"},"Layer 1 :",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Conv 1 : kernel = 7x7x3, stride = 2, no padding, number filter = 96, output = 110x110x96."),(0,r.kt)("li",{parentName:"ul"},"Maxpooling 1 : pooling size = 3x3,stride=2, padding = \u201csame\u201d,output = 55x55x96"),(0,r.kt)("li",{parentName:"ul"},"Normalize layer."))),(0,r.kt)("li",{parentName:"ul"},"Layer 2 :",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Conv 2 : kernel = 5x5x96, stride = 2, no padding, number filter = 256, output = 26x26x256."),(0,r.kt)("li",{parentName:"ul"},"Maxpooling 2 : pooling size = 3x3, stride=2,  padding = \u201csame\u201d,output = 13x13x256"),(0,r.kt)("li",{parentName:"ul"},"Normalize layer."))),(0,r.kt)("li",{parentName:"ul"},"Layer 3:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Conv 3 : kernel = 3x3x256, stride=1, padding=\u201dsame\u201d, number filter = 384,output = 13x13x384."),(0,r.kt)("li",{parentName:"ul"},"Layer 4 :"),(0,r.kt)("li",{parentName:"ul"},"Conv 4 : kernel = 3x3x384, stride=1, padding=\u201dsame\u201d, number filter = 384,output = 13x13x384."))),(0,r.kt)("li",{parentName:"ul"},"Layer 5 :",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Conv 5 : kernel = 3x3x384, stride=1, padding=\u201dsame\u201d, number filter = 256,output = 13x13x256."),(0,r.kt)("li",{parentName:"ul"},"Maxpooling  : pooling size = 3x3,stride =2,padding =\u201dsame\u201d,output = 6x6x256."))),(0,r.kt)("li",{parentName:"ul"},"Flatten 6x6x256 = 9216"),(0,r.kt)("li",{parentName:"ul"},"Fully connected 1 : activation = relu,output =4096"),(0,r.kt)("li",{parentName:"ul"},"Fully connected 2 : activation = relu,output =4096"),(0,r.kt)("li",{parentName:"ul"},"Softmax layer for classifier ouput = 1000")),(0,r.kt)("h2",{id:"4-vggnet2014"},"4. VGGNet(2014)."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Sau AlexNet th\xec VGG ra \u0111\u1eddi v\u1edbi m\u1ed9t s\u1ed1 c\u1ea3i thi\u1ec7n h\u01a1n , tr\u01b0\u1edbc ti\xean l\xe0 model VGG s\u1ebd deeper h\u01a1n, ti\u1ebfp theo l\xe0 thay \u0111\u1ed5i trong th\u1ee9 t\u1ef1 conv. T\u1eeb LeNet \u0111\u1ebfn AlexNet \u0111\u1ec1u s\u1eed d\u1ee5ng Conv-maxpooling c\xf2n VGG th\xec s\u1eed d\u1ee5ng 1 chu\u1ed7i Conv li\xean ti\u1ebfp Conv-Conv-Conv \u1edf middle v\xe0 end c\u1ee7a architect VGG. Vi\u1ec7c n\xe0y s\u1ebd l\xe0m cho vi\u1ec7c t\xednh to\xe1n tr\u1edf n\xean l\xe2u h\u01a1n nh\u01b0ng nh\u1eefng feature s\u1ebd v\u1eabn \u0111\u01b0\u1ee3c gi\u1eef l\u1ea1i nhi\u1ec1u h\u01a1n so v\u1edbi vi\u1ec7c s\u1eed d\u1ee5ng maxpooling sau m\u1ed7i Conv. H\u01a1n n\u1eefa hi\u1ec7n nay v\u1edbi s\u1ef1 ra \u0111\u1eddi c\u1ee7a GPU gi\xfap t\u1ed1c \u0111\u1ed9 t\xednh to\xe1n tr\u1edf n\xean nhanh h\u01a1n r\u1ea5t nhi\u1ec1u l\u1ea7n th\xec v\u1ea5n \u0111\u1ec1 n\xe0y kh\xf4ng c\xf2n \u0111\xe1ng lo ng\u1ea1i. VGG cho small error h\u01a1n AlexNet trong ImageNet Large Scale Visual Recognition Challenge (ILSVRC) n\u0103m 2014. VGG c\xf3 2 phi\xean b\u1ea3n l\xe0 VGG16 v\xe0 VGG19.",(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(1230).Z})),(0,r.kt)("center",null," H\xecnh 5. VGGNet(2014).")),(0,r.kt)("li",{parentName:"ul"},"Architect c\u1ee7a VGG16 bao g\u1ed3m 16 layer :13 layer Conv (2 layer conv-conv,3 layer conv-conv-conv) \u0111\u1ec1u c\xf3 kernel 3x3, sau m\u1ed7i layer conv l\xe0 maxpooling downsize xu\u1ed1ng 0.5, v\xe0 3 layer fully connection. VGG19 t\u01b0\u01a1ng t\u1ef1 nh\u01b0 VGG16 nh\u01b0ng c\xf3 th\xeam 3 layer convolution \u1edf 3 layer conv cu\u1ed1i ( th\xe0nh 4 conv stack v\u1edbi nhau).\nDetail parameter VGG16",(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(747).Z})),(0,r.kt)("center",null," H\xecnh 15. VGG16 ")),(0,r.kt)("li",{parentName:"ul"},"S\u1eed d\u1ee5ng kernel 3x3 thay v\xec 11x11 \u1edf alexnet(7x7 ZFNet). K\u1ebft h\u1ee3p 2 conv 3x3 c\xf3 hi\u1ec3u qu\u1ea3 h\u01a1n 1 cov 5x5 v\u1ec1 receptive field gi\xfap m\u1ea1ng deeper h\u01a1n  l\u1ea1i gi\u1ea3m tham s\u1ed1 t\xednh to\xe1n cho model."),(0,r.kt)("li",{parentName:"ul"},"3 Conv 3x3 c\xf3 receptive field same 1 conv 7x7."),(0,r.kt)("li",{parentName:"ul"},"Input size gi\u1ea3m d\u1ea7n qua c\xe1c conv nh\u01b0ng t\u0103ng s\u1ed1 chi\u1ec1u s\xe2u."),(0,r.kt)("li",{parentName:"ul"},"L\xe0m vi\u1ec7c r\u1ea5t t\u1ed1t cho task classifier v\xe0 localizer ( r\u1ea5t hay \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng trong object detection)."),(0,r.kt)("li",{parentName:"ul"},"S\u1eed d\u1ee5ng relu sau m\u1ed7i conv v\xe0 training b\u1eb1ng batch gradient descent."),(0,r.kt)("li",{parentName:"ul"},"C\xf3 s\u1eed d\u1ee5ng data augmentation technique trong qu\xe1 tr\xecnh training."),(0,r.kt)("li",{parentName:"ul"},"Training v\u1edbi 4 Nvidia Titan Black GPUs trong 2-3 tu\u1ea7n.")),(0,r.kt)("h2",{id:"5-googlenet2014"},"5. GoogleNet(2014)."),(0,r.kt)("p",null,"N\u0103m 2014, google publish m\u1ed9t m\u1ea1ng neural do nh\xf3m research c\u1ee7a h\u1ecd ph\xe1t tri\u1ec3n c\xf3 t\xean l\xe0 googleNet. N\xf3 performance t\u1ed1t h\u01a1n VGG, googleNet 6.7% error rate trong khi VGG l\xe0 7.3%  \xdd t\u01b0\u1edfng ch\xednh l\xe0 h\u1ecd t\u1ea1o ra m\u1ed9t module m\u1edbi c\xf3 t\xean l\xe0 inception gi\xfap m\u1ea1ng traning s\xe2u v\xe0 nhanh h\u01a1n, ch\u1ec9 c\xf3 5m tham s\u1ed1 so v\u1edbi alexnet l\xe0 60m nhanh h\u01a1n g\u1ea5p 12 l\u1ea7n.\nInception module l\xe0 m\u1ed9t m\u1ea1ng CNN gi\xfap training wider(thay v\xec them nhi\u1ec1u layer h\u01a1n v\xec r\u1ea5t d\u1ec5 x\u1ea3y ra overfitting + t\u0103ng parameter ng\u01b0\u1eddi ta ngh\u0129 ra t\u0103ng deeper \u1edf m\u1ed7i t\u1ea7ng layer) so v\u1edbi m\u1ea1ng CNN b\xecnh th\u01b0\u1eddng. M\u1ed7i layer trong CNN truy\u1ec1n th\u1ed1ng s\u1ebd extract c\xe1c th\xf4ng tin kh\xe1c nhau. Output c\u1ee7a 5x5 conv kernel s\u1ebd kh\xe1c v\u1edbi 3x3 kernel. V\u1eady \u0111\u1ec3 l\u1ea5y nh\u1eefng th\xf4ng tin c\u1ea7n thi\u1ebft cho b\xe0i to\xe1n c\u1ee7a ch\xfang ta th\xec n\xean d\xf9ng kernel size nh\u01b0 th\u1ebf n\xe0o ? T\u1ea1i sao ch\xfang s\u1eed d\u1ee5ng t\u1ea5t c\u1ea3 ta v\xe0 sau \u0111\xf3 \u0111\u1ec3 model t\u1ef1 ch\u1ecdn. \u0110\xf3 ch\xednh l\xe0 \xfd t\u01b0\u1edfng c\u1ee7a Inception module, n\xf3  t\xednh to\xe1n c\xe1c kernel size kh\xe1c nhau t\u1eeb m\u1ed9t input sau \u0111\xf3 concatenate n\xf3 l\u1ea1i th\xe0nh output. "),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(6477).Z})),(0,r.kt)("center",null," H\xecnh 6. Inception. "),(0,r.kt)("p",null,"Trong inception ng\u01b0\u1eddi ta d\xf9ng conv kernel 1x1 v\u1edbi 2 m\u1ee5c \u0111\xedch l\xe0 gi\u1ea3m tham s\u1ed1 t\xednh to\xe1n v\xe0 dimensionality reduction . Dimensionality reduction c\xf3 th\u1ec3 hi\u1ec3u l\xe0m gi\u1ea3m depth c\u1ee7a input (vd iput 28x28x100 qua kernel 1x1 v\u1edbi filter = 10 s\u1ebd gi\u1ea3m depth v\u1ec1 c\xf2n 28x28x10). Gi\u1ea3m chi ph\xed t\xednh to\xe1n c\xf3 th\u1ec3  hi\u1ec3u qua v\xed d\u1ee5 sau :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Input shape 28x28x192 qua kernel 5x5 v\u1edbi 32 th\xec ouput l\xe0 28x28x32(padding same) th\xec  tham s\u1ed1 t\xednh to\xe1n l\xe0 (5x5x192)*(28x28x32)=120 million"),(0,r.kt)("li",{parentName:"ul"},"Input shape 28x28x192 qua kernel 1x1x192 filter = 16 , output = 28x28x16 ti\u1ebfp t\u1ee5c v\u1edbi kernel 5x5x32 filter = 16 \u0111\u01b0\u01a1ch output = 28x28x32. T\u1ed5ng tham s\u1ed1 t\xednh to\xe1n : ",(0,r.kt)("span",{parentName:"li",className:"math math-inline"},(0,r.kt)("span",{parentName:"span",className:"katex"},(0,r.kt)("span",{parentName:"span",className:"katex-mathml"},(0,r.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,r.kt)("semantics",{parentName:"math"},(0,r.kt)("mrow",{parentName:"semantics"},(0,r.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,r.kt)("mn",{parentName:"mrow"},"28"),(0,r.kt)("mi",{parentName:"mrow"},"x"),(0,r.kt)("mn",{parentName:"mrow"},"28"),(0,r.kt)("mi",{parentName:"mrow"},"x"),(0,r.kt)("mn",{parentName:"mrow"},"16"),(0,r.kt)("mo",{parentName:"mrow",stretchy:"false"},")"),(0,r.kt)("mo",{parentName:"mrow"},"\u2217"),(0,r.kt)("mn",{parentName:"mrow"},"192"),(0,r.kt)("mo",{parentName:"mrow"},"+"),(0,r.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,r.kt)("mn",{parentName:"mrow"},"28"),(0,r.kt)("mi",{parentName:"mrow"},"x"),(0,r.kt)("mn",{parentName:"mrow"},"28"),(0,r.kt)("mi",{parentName:"mrow"},"x"),(0,r.kt)("mn",{parentName:"mrow"},"32"),(0,r.kt)("mo",{parentName:"mrow",stretchy:"false"},")"),(0,r.kt)("mo",{parentName:"mrow"},"\u2217"),(0,r.kt)("mo",{parentName:"mrow",stretchy:"false"},"("),(0,r.kt)("mn",{parentName:"mrow"},"5"),(0,r.kt)("mi",{parentName:"mrow"},"x"),(0,r.kt)("mn",{parentName:"mrow"},"5"),(0,r.kt)("mi",{parentName:"mrow"},"x"),(0,r.kt)("mn",{parentName:"mrow"},"16"),(0,r.kt)("mo",{parentName:"mrow",stretchy:"false"},")"),(0,r.kt)("mo",{parentName:"mrow"},"="),(0,r.kt)("mn",{parentName:"mrow"},"2.4"),(0,r.kt)("mo",{parentName:"mrow"},"+"),(0,r.kt)("mn",{parentName:"mrow"},"10"),(0,r.kt)("mo",{parentName:"mrow"},"="),(0,r.kt)("mn",{parentName:"mrow"},"12.4"),(0,r.kt)("mi",{parentName:"mrow"},"m"),(0,r.kt)("mi",{parentName:"mrow"},"i"),(0,r.kt)("mi",{parentName:"mrow"},"l"),(0,r.kt)("mi",{parentName:"mrow"},"l"),(0,r.kt)("mi",{parentName:"mrow"},"i"),(0,r.kt)("mi",{parentName:"mrow"},"o"),(0,r.kt)("mi",{parentName:"mrow"},"n"),(0,r.kt)("mi",{parentName:"mrow",mathvariant:"normal"},".")),(0,r.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"(28x28x16)*192 + (28x28x32)*(5x5x16) = 2.4 + 10 = 12.4 million.")))),(0,r.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.kt)("span",{parentName:"span",className:"mopen"},"("),(0,r.kt)("span",{parentName:"span",className:"mord"},"28"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,r.kt)("span",{parentName:"span",className:"mord"},"28"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,r.kt)("span",{parentName:"span",className:"mord"},"16"),(0,r.kt)("span",{parentName:"span",className:"mclose"},")"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.kt)("span",{parentName:"span",className:"mbin"},"\u2217"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,r.kt)("span",{parentName:"span",className:"mord"},"192"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.kt)("span",{parentName:"span",className:"mbin"},"+"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.kt)("span",{parentName:"span",className:"mopen"},"("),(0,r.kt)("span",{parentName:"span",className:"mord"},"28"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,r.kt)("span",{parentName:"span",className:"mord"},"28"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,r.kt)("span",{parentName:"span",className:"mord"},"32"),(0,r.kt)("span",{parentName:"span",className:"mclose"},")"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.kt)("span",{parentName:"span",className:"mbin"},"\u2217"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.kt)("span",{parentName:"span",className:"mopen"},"("),(0,r.kt)("span",{parentName:"span",className:"mord"},"5"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,r.kt)("span",{parentName:"span",className:"mord"},"5"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"x"),(0,r.kt)("span",{parentName:"span",className:"mord"},"16"),(0,r.kt)("span",{parentName:"span",className:"mclose"},")"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,r.kt)("span",{parentName:"span",className:"mrel"},"="),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7278em",verticalAlign:"-0.0833em"}}),(0,r.kt)("span",{parentName:"span",className:"mord"},"2.4"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.kt)("span",{parentName:"span",className:"mbin"},"+"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2222em"}})),(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6444em"}}),(0,r.kt)("span",{parentName:"span",className:"mord"},"10"),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,r.kt)("span",{parentName:"span",className:"mrel"},"="),(0,r.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,r.kt)("span",{parentName:"span",className:"base"},(0,r.kt)("span",{parentName:"span",className:"strut",style:{height:"0.6944em"}}),(0,r.kt)("span",{parentName:"span",className:"mord"},"12.4"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"mi"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.01968em"}},"ll"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"i"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"o"),(0,r.kt)("span",{parentName:"span",className:"mord mathnormal"},"n"),(0,r.kt)("span",{parentName:"span",className:"mord"},"."))))),"\nTa th\u1ea5y v\u1edbi c\xf9ng output l\xe0 28x28x32 th\xec n\u1ebfu d\xf9ng kernel 5x5x192 v\u1edbi 32 filter th\xec s\u1ebd c\xf3 tham s\u1ed1 g\u1ea5p 10 l\u1ea7n so v\u1edbi s\u1eed d\u1ee5ng kernel 1x1x192 sau \u0111\xf3 d\xf9ng ti\u1ebfp 1 kernel 5x5x16 v\u1edbi filter 32.\nInception hi\u1ec7n gi\u1edd c\xf3 4 version , ta s\u1ebd c\xf9ng t\xecm hi\u1ec3u s\u01a1 qua c\xe1c version:"),(0,r.kt)("li",{parentName:"ul"},"Inception v1 : c\xf3 2 d\u1ea1ng  l\xe0 na\xefve v\xe0 dimension reduction. Kh\xe1c bi\u1ec7t ch\xednh \u0111\xf3 l\xe0 version dimension reduction n\xf3 d\xf9ng conv 1x1 \u1edf m\u1ed7i layer \u0111\u1ec3 gi\u1ea3m depth c\u1ee7a input gi\xfap model c\xf3 \xedt tham s\u1ed1 h\u01a1n. Inception na\xefve c\xf3 architect g\u1ed3m 1x1 conv,3x3  conv, 5x5 conv v\xe0 3x3 maxpooling.",(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(8617).Z})))),(0,r.kt)("center",null," H\xecnh 7. Inception V1."),(0,r.kt)("p",null,"Inception v2 : C\u1ea3i thi\u1ec7n version 1, th\xeam layer batchnormalize v\xe0 gi\u1ea3m Internal Covariate Shift. Ouput c\u1ee7a m\u1ed7i layer s\u1ebd \u0111\u01b0\u1ee3c normalize v\u1ec1 Gaussian N(0,1). Conv 5x5 s\u1ebd \u0111\u01b0\u1ee3c thay th\u1ebf b\u1eb1ng 2 conv 3x3 \u0111\u1ec3 gi\u1ea3m computation cost."),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(1237).Z})),(0,r.kt)("center",null," H\xecnh 8. Inception V2. "),(0,r.kt)("p",null,"Inception v3 : \u0110i\u1ec3m \u0111\xe1ng ch\xfa \xfd \u1edf version n\xe0y l\xe0 Factorization. Conv 7x7 s\u1ebd \u0111\u01b0\u1ee3c gi\u1ea3m v\u1ec1 conv 1 dimesion l\xe0 (1x7),(7x1). T\u01b0\u01a1ng t\u1ef1 conv 3x3 (3x1,1x3). T\u0103ng t\u1ed1c \u0111\u1ed9 t\xednh to\xe1n. Khi t\xe1ch ra 2 conv th\xec l\xe0m model deeper h\u01a1n."),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(8406).Z})),(0,r.kt)("center",null," H\xecnh 9. Inception V3. "),"Inception v4 : l\xe0 s\u1ef1 k\u1ebft h\u1ee3p inception v\xe0 resnet. Detail googleNet architect :",(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(1712).Z})),(0,r.kt)("center",null," H\xecnh 10. GoogleNet."),"GoogleNet g\u1ed3m 22 layer, kh\u1edfi \u0111\u1ea7u v\u1eabn l\xe0 nh\u1eefng simple convolution layer, ti\u1ebfp theo l\xe0 nh\u1eefng block c\u1ee7a inception module v\u1edbi maxpooling theo sau m\u1ed7i block. M\u1ed9t s\u1ed1 \u0111\u1eb7c \u0111i\u1ec3m ch\xednh. * S\u1eed d\u1ee5ng 9 Inception module tr\xean to\xe0n b\u1ed9 architect. L\xe0m model deeper h\u01a1n r\u1ea5t nhi\u1ec1u. * Kh\xf4ng s\u1eed d\u1ee5ng fully connection layer m\xe0 thay v\xe0o \u0111\xf3 l\xe0 average pooling t\u1eeb 7x7x1024 volume th\xe0nh 1x1x1024 volume gi\u1ea3m thi\u1ec3u \u0111\u01b0\u1ee3c r\u1ea5t nhi\u1ec1u parameter. * \xcdt h\u01a1n 12x parameter so v\u1edbi Alexnet. * Auxiliary Loss \u0111\u01b0\u1ee3c add v\xe0o total loss(weight =0.3). Nh\u01b0ng \u0111\u01b0\u1ee3c lo\u1ea1i b\u1ecf khi test.",(0,r.kt)("h2",{id:"6-resnets2015"},"6. ResNets(2015)."),(0,r.kt)("p",null,"ResNet \u0111\u01b0\u1ee3c ph\xe1t tri\u1ec3n b\u1edfi microsoft n\u0103m 2015 v\u1edbi paper \u201c Deep residual learning for image recognition\u201d. ResNet winer ImageNet ILSVRC competition 2015 v\u1edbi error rate 3.57% ,ResNet c\xf3 c\u1ea5u tr\xfac g\u1ea7n gi\u1ed1ng VGG v\u1edbi nhi\u1ec1u stack layer l\xe0m cho model deeper h\u01a1n. Kh\xf4ng gi\u1ed1ng VGG, resNet  c\xf3 depth s\xe2u h\u01a1n nh\u01b0 34,55,101 v\xe0 151 . Resnet gi\u1ea3i quy\u1ebft \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 c\u1ee7a deep learning truy\u1ec1n th\u1ed1ng , n\xf3 c\xf3 th\u1ec3 d\u1ec5 d\xe0ng training model v\u1edbi h\xe0ng tr\u0103m layer. \u0110\u1ec3 hi\u1ec3u ResNet ch\xfang ta c\u1ea7n hi\u1ec3u v\u1ea5n \u0111\u1ec1 khi stack nhi\u1ec1u layer khi training, v\u1ea5n \u0111\u1ec1 \u0111\u1ea7u ti\xean khi t\u0103ng model deeper h\u01a1n gradient s\u1ebd b\u1ecb vanishing/explodes. V\u1ea5n \u0111\u1ec1 n\xe0y c\xf3 th\u1ec3 gi\u1ea3i quy\u1ebft b\u1eb1ng c\xe1ch th\xeam Batch Normalization n\xf3 gi\xfap normalize output gi\xfap c\xe1c h\u1ec7 s\u1ed1 tr\u1edf n\xean c\xe2n b\u1eb1ng h\u01a1n kh\xf4ng qu\xe1 nh\u1ecf ho\u1eb7c qu\xe1 l\u1edbn n\xean s\u1ebd gi\xfap model d\u1ec5 h\u1ed9i t\u1ee5 h\u01a1n. V\u1ea5n \u0111\u1ec1 th\u1ee9 2 l\xe0  degradation, Khi model deeper accuracy b\u1eaft \u0111\u1ea7u b\xe3o h\xf2a(saturated) th\u1eadm ch\xed l\xe0 gi\u1ea3m. Nh\u01b0 h\xecnh v\u1ebd b\xean d\u01b0\u1edbi khi stack nhi\u1ec1u layer h\u01a1n th\xec training error l\u1ea1i cao h\u01a1n \xedt layer nh\u01b0 v\u1eady v\u1ea5n \u0111\u1ec1 kh\xf4ng ph\u1ea3i l\xe0 do overfitting. V\u1ea5n \u0111\u1ec1 n\xe0y l\xe0 do model kh\xf4ng d\u1ec5 training kh\xf3 h\u1ecdc h\u01a1n, th\u1eed t\u01b0\u1ee3ng t\u01b0\u1ee3ng m\u1ed9t training m\u1ed9t shallow model, sau \u0111\xf3 ch\xfang ta stack th\xeam nhi\u1ec1u layer , c\xe1c layer sau khi th\xeam v\xe0o s\u1ebd kh\xf4ng h\u1ecdc th\xeam \u0111\u01b0\u1ee3c g\xec c\u1ea3 (identity mapping) n\xean accuracy s\u1ebd t\u01b0\u01a1ng t\u1ef1 nh\u01b0 shallow model m\xe0 kh\xf4ng t\u0103ng. Resnet \u0111\u01b0\u1ee3c ra \u0111\u1eddi \u0111\u1ec3 gi\u1ea3i quy\u1ebft v\u1ea5n \u0111\u1ec1 degradation n\xe0y."),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(306).Z})),(0,r.kt)("center",null," H\xecnh 11. Compare accuracy with "),"ResNet c\xf3 architecture g\u1ed3m nhi\u1ec1u residual block, \xfd t\u01b0\u1edfng ch\xednh l\xe0 skip layer b\u1eb1ng c\xe1ch add connection v\u1edbi layer tr\u01b0\u1edbc. \xdd t\u01b0\u1edfng c\u1ee7a residual block l\xe0 feed foword x(input) qua m\u1ed9t s\u1ed1 layer conv-max-conv, ta thu \u0111\u01b0\u1ee3c F(x) sau \u0111\xf3 add th\xeam x v\xe0o H(x) = F(x) + x . Model s\u1ebd d\u1ec5 h\u1ecdc h\u01a1n khi ch\xfang ta th\xeam feature t\u1eeb layer tr\u01b0\u1edbc v\xe0o.",(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(3724).Z})),(0,r.kt)("center",null," H\xecnh 12. ResNets block. "),"* S\u1eed d\u1ee5ng batch Normalization sau m\u1ed7i Conv layer. * Initialization Xavier/2 * Training v\u1edbi SGD + momentum(0.9) * Learning rate 0.1, gi\u1ea3m 10 l\u1ea7n n\u1ebfu error ko gi\u1ea3m * Mini batch size 256 * Weight decay 10^-5 * Kh\xf4ng s\u1eed d\u1ee5ng dropout",(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(3135).Z})),(0,r.kt)("center",null," H\xecnh 13. ResNets(2015). "),(0,r.kt)("h2",{id:"7-densenet2016"},"7. Densenet(2016)"),(0,r.kt)("p",null,"Densenet(Dense connected convolutional network) l\xe0 m\u1ed9t trong nh\u1eefng netwok m\u1edbi nh\u1ea5t cho visual object recognition. N\xf3 c\u0169ng g\u1ea7n gi\u1ed1ng Resnet nh\u01b0ng c\xf3 m\u1ed9t v\xe0i \u0111i\u1ec3m kh\xe1c bi\u1ec7t. Densenet c\xf3 c\u1ea5u tr\xfac g\u1ed3m c\xe1c dense block v\xe0 c\xe1c transition layers. \u0110\u01b0\u1ee3c stack dense block- transition layers-dense block- transition layers nh\u01b0 h\xecnh v\u1ebd. V\u1edbi CNN truy\u1ec1n th\u1ed1ng n\u1ebfu ch\xfang ta c\xf3 L layer th\xec s\u1ebd c\xf3 L connection, c\xf2n trong densenet s\u1ebd c\xf3 L(L+1)/2 connection."),(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(2434).Z})),(0,r.kt)("center",null," H\xecnh 14. Densenet(2016). "),"H\xe3y t\u01b0\u1edfng t\u01b0\u1ee3ng ban \u0111\u1ea7u ta c\xf3 1 image size (28,28,3). \u0110\u1ea7u ti\xean ta kh\u1edfi t\u1ea1o feature layer b\u1eb1ng Conv t\u1ea1o ra 1 layer size (28,28,24). Sau m\u1ed7i layer ti\u1ebfp theo (Trong dense block ) n\xf3 s\u1ebd t\u1ea1o th\xeam K= 12 feature gi\u1eefa nguy\xean width v\xe0 height. Khi \u0111\xf3 output ti\u1ebfp theo s\u1ebd l\xe0 (28,28,24 +12),(28,28,24 +12+12). \u1ede m\u1ed7i dense block s\u1ebd c\xf3 normalization, nonlinearity v\xe0 dropout. \u0110\u1ec3 gi\u1ea3m size v\xe0 depth c\u1ee7a feature th\xec transition layer \u0111\u01b0\u1ee3c \u0111\u1eb7t gi\u1eefa c\xe1c dense block, n\xf3 g\u1ed3m Conv kernel size =1, average pooling (2x2) v\u1edbi stride = 2 n\xf3 s\u1ebd gi\u1ea3m output th\xe0nh (14,14,48)",(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(1654).Z})),"Detail parameter :",(0,r.kt)("center",null,(0,r.kt)("img",{width:"600",height:"300",src:e(4172).Z})),"M\u1ed9t s\u1ed1 \u01b0u \u0111i\u1ec3m c\u1ee7a Densenet: * Accuracy : Densenet training tham s\u1ed1 \xedt h\u01a1n 1 n\u1eeda so v\u1edbi Resnet nh\u01b0ng c\xf3 same accuracy so tr\xean ImageNet classification dataset. * Overfitting : DenseNet resistance overfitting r\u1ea5t hi\u1ec7u qu\u1ea3. * Gi\u1ea3m \u0111\u01b0\u1ee3c vashing gradient. * S\u1eed d\u1ee5ng l\u1ea1i feature hi\u1ec7u qu\u1ea3 h\u01a1n. ## K\u1ebft b\xe0i : Tr\xean \u0111\xe2y ch\u1ec9 l\xe0 ph\u1ea7n t\xf3m l\u01b0\u1ee3c s\u01a1 qua c\xe1c architect n\u1ed5i ti\u1ebfng c\u1ee7a CNN. B\xean trong \u0111\xf3 c\xf2n c\xf3 nhi\u1ec1u c\u1ea5u tr\xfac ph\u1ee9c t\u1ea1p v\xec th\u1eddi gian c\u0169ng nh\u01b0 ki\u1ebfn th\u1ee9c c\xf3 h\u1ea1n n\xean v\u1eabn ch\u01b0a vi\u1ebft s\xe2u h\u1ebft \u0111\u01b0\u1ee3c. B\xean c\u1ea1nh \u0111\xf3 c\xf2n c\xf3 nhi\u1ec1u sai s\xf3t r\u1ea5t mong b\u1ea1n \u0111\u1ecdc g\xf3p \xfd \u0111\u1ec3 m\xecnh c\xf3 th\u1ec3 ho\xe0n thi\u1ec7n b\xe0i vi\u1ebft h\u01a1n.",(0,r.kt)("p",null,"Tham kh\u1ea3o : "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Deep learning course : Andrew Ng"),(0,r.kt)("li",{parentName:"ul"},"An Intuitive Guide to Deep Network Architectures : Joyce Xu"),(0,r.kt)("li",{parentName:"ul"},"A Simple Guide to the Versions of the Inception Network :Bharath Raj"),(0,r.kt)("li",{parentName:"ul"},"CS231n: Convolutional Neural Networks for Visual Recognition"),(0,r.kt)("li",{parentName:"ul"},"Paper : All paper about lenet,alexnet,vgg,googlenet,resnet,densenet"),(0,r.kt)("li",{parentName:"ul"},"Notes on the Implementation of DenseNet in TensorFlow."),(0,r.kt)("li",{parentName:"ul"},"The Efficiency of Densenet")))}u.isMDXComponent=!0},103:function(n,t,e){t.Z=e.p+"assets/images/36767372_240415716555330_8179137527236526080_n-4b5f05ec55635c4875809140660b79f7.png"},4502:function(n,t,e){t.Z=e.p+"assets/images/36774671_240413323222236_1459661677975830528_n-5c52132447d62047444e2d112bb13c90.png"},980:function(n,t,e){t.Z=e.p+"assets/images/36833992_240414163222152_4178930615535534080_n-fe7855077a16b7a10a600b8a72e9bb66.png"},1230:function(n,t,e){t.Z=e.p+"assets/images/cnn10-b35d02ca5c1001b4fddbadcc247c2f86.jpg"},306:function(n,t,e){t.Z=e.p+"assets/images/cnn11-1abc704b895f11dae66cd54657e4a06f.jpg"},3724:function(n,t,e){t.Z=e.p+"assets/images/cnn12-aa3a1b29e26280f747bdee931342a667.jpg"},3135:function(n,t,e){t.Z=e.p+"assets/images/cnn13-d87a69dc04e947eb0e6f8892f297c2ef.jpg"},2434:function(n,t,e){t.Z=e.p+"assets/images/cnn14-90b19af67a72e5b3889e99a34ef2f224.jpg"},747:function(n,t,e){t.Z=e.p+"assets/images/cnn15-f72ebbec5dad712981c35a80cf7b173b.jpg"},1654:function(n,t,e){t.Z=e.p+"assets/images/cnn16-3ce428a688920ba5e5b38f2cbe5adc9a.jpg"},4172:function(n,t,e){t.Z=e.p+"assets/images/cnn17-3506982af4a117fc86278b47dd6824e4.jpg"},6702:function(n,t,e){t.Z=e.p+"assets/images/cnn4-2828b3f608b90f11a278b7a8a37cb10b.jpg"},6477:function(n,t,e){t.Z=e.p+"assets/images/cnn5-32e573dcf8abba41d300b7c62574be8c.jpg"},8617:function(n,t,e){t.Z=e.p+"assets/images/cnn6-ebb444df634b449d04ce07dd8d35cdc4.jpg"},1237:function(n,t,e){t.Z=e.p+"assets/images/cnn7-bd4a80868149bac6d7e935b1a122243b.jpg"},8406:function(n,t,e){t.Z=e.p+"assets/images/cnn8-f46ac346cb6382ce2cc5d06985163d2a.jpg"},1712:function(n,t,e){t.Z=e.p+"assets/images/cnn9-f72ebbec5dad712981c35a80cf7b173b.jpg"}}]);