<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Object detection từ R-CNN đến Faster R-CNN | ThorPham</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://thorpham.github.io/blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Object detection từ R-CNN đến Faster R-CNN | ThorPham"><meta data-rh="true" name="description" content="Như chúng ta đã biết object detection bao gồm 2 nhiệm vụ chính là Classifier và Localization. Trong đó nhiệm vụ có vẻ khó khăn hơn là Localization. Trước khi deep learning phát triển như hiện nay, trong computer vision người ta detection object qua 2 giai đoạn. Đầu tiên là trích xuất feature từ hog,lbp,sift sau đó dùng các thuật toán trong machine learning như SVM để classifier. Bước tiếp theo là detection object trên ảnh lớn thì người ta sẽ dùng 1 window search trên toàn bộ bức ảnh sau đó dùng model đã classifier để phân lớp object. Các model này có ưu điểm là thời gian build model tương đối nhanh, cần ít dữ liệu . Nhược điểm là độ chính xác không cao và thời gian predict rất lâu nên khó có thể dùng trong real time."><meta data-rh="true" property="og:description" content="Như chúng ta đã biết object detection bao gồm 2 nhiệm vụ chính là Classifier và Localization. Trong đó nhiệm vụ có vẻ khó khăn hơn là Localization. Trước khi deep learning phát triển như hiện nay, trong computer vision người ta detection object qua 2 giai đoạn. Đầu tiên là trích xuất feature từ hog,lbp,sift sau đó dùng các thuật toán trong machine learning như SVM để classifier. Bước tiếp theo là detection object trên ảnh lớn thì người ta sẽ dùng 1 window search trên toàn bộ bức ảnh sau đó dùng model đã classifier để phân lớp object. Các model này có ưu điểm là thời gian build model tương đối nhanh, cần ít dữ liệu . Nhược điểm là độ chính xác không cao và thời gian predict rất lâu nên khó có thể dùng trong real time."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2018-08-08T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/ThorPham"><meta data-rh="true" property="article:tag" content="Object detection,CNN"><link data-rh="true" rel="icon" href="/img/emoticon_big.png"><link data-rh="true" rel="canonical" href="https://thorpham.github.io/blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN"><link data-rh="true" rel="alternate" href="https://thorpham.github.io/blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN" hreflang="en"><link data-rh="true" rel="alternate" href="https://thorpham.github.io/blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://thorpham.github.io/blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN","mainEntityOfPage":"https://thorpham.github.io/blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN","url":"https://thorpham.github.io/blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN","headline":"Object detection từ R-CNN đến Faster R-CNN","name":"Object detection từ R-CNN đến Faster R-CNN","description":"Như chúng ta đã biết object detection bao gồm 2 nhiệm vụ chính là Classifier và Localization. Trong đó nhiệm vụ có vẻ khó khăn hơn là Localization. Trước khi deep learning phát triển như hiện nay, trong computer vision người ta detection object qua 2 giai đoạn. Đầu tiên là trích xuất feature từ hog,lbp,sift sau đó dùng các thuật toán trong machine learning như SVM để classifier. Bước tiếp theo là detection object trên ảnh lớn thì người ta sẽ dùng 1 window search trên toàn bộ bức ảnh sau đó dùng model đã classifier để phân lớp object. Các model này có ưu điểm là thời gian build model tương đối nhanh, cần ít dữ liệu . Nhược điểm là độ chính xác không cao và thời gian predict rất lâu nên khó có thể dùng trong real time.","datePublished":"2018-08-08T00:00:00.000Z","author":{"@type":"Person","name":"Thorpham","description":"Deep learning enthusiast","url":"https://github.com/ThorPham","image":"https://github.com/ThorPham.png"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://thorpham.github.io/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="ThorPham RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="ThorPham Atom Feed">





<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.81292009.css">
<script src="/assets/js/runtime~main.367e03ce.js" defer="defer"></script>
<script src="/assets/js/main.be6f4518.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/emoticon_big.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/emoticon_big.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Thorpham</b></a><a class="navbar__item navbar__link" href="/cs/intro">CS</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/ThorPham" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1"><article class=""><header><h1 class="title_f1Hy">Object detection từ R-CNN đến Faster R-CNN</h1><div class="container_mt6G margin-vert--md"><time datetime="2018-08-08T00:00:00.000Z">August 8, 2018</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/ThorPham" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://github.com/ThorPham.png" alt="Thorpham"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/ThorPham" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Thorpham</span></a></div><small class="authorTitle_nd0D" title="Deep learning enthusiast">Deep learning enthusiast</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p><em>Như chúng ta đã biết object detection bao gồm 2 nhiệm vụ chính là Classifier và Localization. Trong đó nhiệm vụ có vẻ khó khăn hơn là Localization. Trước khi deep learning phát triển như hiện nay, trong computer vision người ta detection object qua 2 giai đoạn. Đầu tiên là trích xuất feature từ hog,lbp,sift sau đó dùng các thuật toán trong machine learning như SVM để classifier. Bước tiếp theo là detection object trên ảnh lớn thì người ta sẽ dùng 1 window search trên toàn bộ bức ảnh sau đó dùng model đã classifier để phân lớp object. Các model này có ưu điểm là thời gian build model tương đối nhanh, cần ít dữ liệu . Nhược điểm là độ chính xác không cao và thời gian predict rất lâu nên khó có thể dùng trong real time.</em></p>
<p>Với tộc độ phát triển như hiện nay , dữ liệu của chúng ta ngày càng nhiều và các bài toán bắt đầu khó dần lên nên những model truyền thống tỏ ra kém hiệu quả. Các feature lấy ra từ computer vision truyền thống như hog,sift,lbp là những shadow feature nó chỉ lấy được những feature trên bề mặt nổi image mà thôi, do đó những bài toán như classifer con chó hay con mèo thì những feature này làm việc tương đối hiệu quả , nhưng nâng cấp bài toán lên đó là classifier con bull dog hay con béc rê thì những feature này làm việc kém hiệu quả. Cũng dễ hiểu vì cùng 1 class là dog thì những feature này tương đối giống nhau nên khó có thể phân biệt được con này con kia. Chính vì thế ta cần những feature sâu hơn, những feature mà nó ẩn ở trong image mà ta khó có thể quan sát được bằng mắt thường để phân biệt dog này hay dog kia. Trong deep learning , object detection nền tảng cơ bản là dựa trên mạng CNN để lấy những deep feature bằng cách đưa qua nhiều layer khác nhau feature được extract sâu hơn sau đó được đưa vào classifier và regression box. Hai hướng tiếp cận chính trong deep learning là :</p>
<ul>
<li>Chia image ra thành những grid cell SxS . Mỗi cell được coi như region proposal giúp giảm thời gian và chi phí tính toán thay vì sử dụng trực tiếp image ( model SSD,YOLO)</li>
<li>Tìm những region proposal có nhiều khẳn năng chứa object nhất sử dụng selective search hay RPN ( model R-CNN,Fast R-CNN, Faster R-CNN)</li>
</ul>
<p>Trong bài này chúng ta sẽ tìm hiểu về các họ nhà CNN cho object detection.</p>
<center><img width="600" height="300" src="/assets/images/35474711_223243181605917_1003697740695207936_n-aa4c8770a68789d1549024a2ec3f4950.png"></center>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-r-cnn">1. R-CNN<a href="#1-r-cnn" class="hash-link" aria-label="Direct link to 1. R-CNN" title="Direct link to 1. R-CNN">​</a></h2>
<center><img width="600" height="300" src="/assets/images/35329075_223246958272206_8520772647733166080_n-0008f462f66954c8692ad2fe21121dd2.png"></center>
<p>R-CNN là viết tắt của “Region-based Convolutional Neural Networks”. Ý tưởng chính của nó gồm 2 phần : Đầu tiên là dùng selective search tìm các region of interest (roi) trên image để tạo ra các bounding box mà có xác suất cao là có object. Sau đó dùng CNN để lấy feature từ các region này để classifier và regression  box. Các bước thực hiện như sau :</p>
<ul>
<li>Từ input image ta dùng selective search để lấy cái region proposal .Selective Search nó hoạt động bằng cách là đầu tiên tạo ra các seed là các region segementation trên image(trong skimage họ dùng Felsenszwalb’s efficient graph based image segmentation) Các region sau đó sẽ được merger lại với nhau bằng cách tính độ tương đồng về color,shape,textuture… Cuối cùng ta vẽ bounding box cho từng region.Mỗi image người ta sẽ lấy tầm 2k region proposal.</li>
<li>Tiếp đến các region proposal sẽ được swarped(crop) để fix size(vì một số mạng như VGG yêu cầu size input là cố định,hơn nữa ta cần feature output same size). Sau đó dùng CNN( VGG,Alexnet) để lấy feature.</li>
<li>Cuối cùng là dùng SVM để classifier và regression bounding box
Nhược điểm của phương pháp này là training rất lâu vì 2k image qua CNN để lấy feature mất rất nhiều thời gian (52 s trên cpu) .</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-spp-net">2. SPP net<a href="#2-spp-net" class="hash-link" aria-label="Direct link to 2. SPP net" title="Direct link to 2. SPP net">​</a></h2>
<center><img width="600" height="300" src="/assets/images/35346991_223247254938843_4269602627899097088_n-1104a3ea805cf4d3708d2aa328e04667.png"></center>
<p>Thay vì feed forword 2k image qua CNN thì người ta feed forwork qua CNN một lần để lấy feature map (feature map = feature + location). Sau đó dùng selective search để tìm region proposal, rồi project trên feature map để lấy feature tương ứng. Có một vấn đề ở đây là các feature map của region proposal có size khác nhau nên khi đưa qua CNN sẽ có length output khác nhau. Vì vậy người ta sử dụng Spatial paramy pooling layer để  fix size feature.(spp layer hoạt động  cũng tương tự bag of word trong image processing nó sẽ chia feature theo Spatial pyramid và áp dụng max pooling theo từng spatial giúp các feature có size khác nhau thành same size). Phần sau còn lại tương tự như R-CNN</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-fast-r-cnn">3. Fast R-CNN<a href="#3-fast-r-cnn" class="hash-link" aria-label="Direct link to 3. Fast R-CNN" title="Direct link to 3. Fast R-CNN">​</a></h2>
<center><img width="600" height="300" src="/assets/images/35348615_223247421605493_4297776049992761344_n-1eb38bea200f935c0b6f9f4ff7dc5ed1.png"></center>
<p>Fast R-CNN cải thiện được các nhược điểm của R-CNN bằng cách hợp nhất 3 model độc lập vốn rất chậm chạp. Nó cũng có phần giống SPP-net là dùng CNN để lấy feature map một lần thay vì dùng riêng cho mỗi region proposal. Sau đó những feature này sẽ được đưa qua một Fully connection layer để classifier và regression bounding box. Model này tương đối nhanh chạy 2s/image.
Các bước thức hiện thuật toán :</p>
<ul>
<li>Dùng pretraining model (VGG,ZF…) để lấy feature map.</li>
<li>Sử dụng selective search để lấy region proposal (~2k image). Sau đó project lên feature map để lấy feature tương ứng</li>
<li>Feature sẽ được đưa qua ROI pooling để fix size.</li>
<li>Cuối cùng Fully connection layer để classifier và regression box</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-faster-r-cnn">4. Faster R-CNN<a href="#4-faster-r-cnn" class="hash-link" aria-label="Direct link to 4. Faster R-CNN" title="Direct link to 4. Faster R-CNN">​</a></h2>
<center><img width="600" height="300" src="/assets/images/35326994_223247604938808_7752372882168086528_n-884aea70061745f6ba6243a5c75ecdb5.png"></center>
<p>Faster R-CNN gồm region proposal network ( nó thay thế cho selective search) và phần còn lại tương tự như Fast R-CNN. Region proposal network(RPN) nó dùng 1 sliding window search trên feature map để tạo các anchor box. Sau đó chúng ta chuẩn bị data training cho RPN bằng cách gán nhãn cho mỗi anchor box dựa vào iou với ground truth. Cuối cùng dùng data này để classifier và regression bounding box. Ta thu được rất nhiều bounding box và dùng non maximum suppression(NMS) để loại bỏ bớt đi những box không có nhiều khẳn năng chứa object. Sau đó những bounding box này sẽ tương tự như selective search ở fast R-CNN nó được đưa qua ROI pooling để fix size và cuối cùng đưa vào fully connection layer để classifier (xác định object cụ thể) và regression box. Model này tương đối nhanh predict 0.2s/image(gpu)
Model gồm các bước sau :
Pretrain model CNN để lấy feature map.</p>
<ul>
<li>Training RPN để tìm bouding box và classifier (chỉ xác định là object và non-object không classifier cụ thể object). Một siliding window size NxM search trên feature map. Tại mỗi center của window, ta predict mutil region với scale và ratio khác nhau. Thông thường là 3 scale và 3 ratio nên tạo ra 9 anchor box. Positive sample IOU &gt; 0.7, negative sample IOU &lt; 0.3.</li>
<li>Dùng data này training để classifier và regression . Vì số background nhiều nên để hạn chế bias người ta dùng mini bath để training mỗi lần đưa vào tỉ lệ một pos và neg nhất định. Sau đó loại bớt bounding box có ít khẳn năng chứa object bằng NMS.</li>
<li>Ta project bounding box lên feature map để lấy feature tương ứng sau đó đưa vào ROI pooling layer fix size để đưa vào Fully connection layer để classifier từng object và regression box.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-kết-luận">5. Kết luận<a href="#5-kết-luận" class="hash-link" aria-label="Direct link to 5. Kết luận" title="Direct link to 5. Kết luận">​</a></h2>
<p>Trên đây mới chỉ là một bài giới thiệu sơ qua về cách hoạt động của R-CNN đến Faster R-CNN. Bên trong cấu trúc của mỗi model này tương đối phức tạp. Nếu có thể mình sẽ viết chi tiết cách hoạt động của từng model qua các bài sau.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/object-detection">Object detection</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/cnn">CNN</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/ThorPham/blog/2018-8-8-Object-detection-từ-R-CNN-đến-Faster-R-CNN/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/Quá-trình-phát-triển-của-CNN-từ-LeNet-đến-DenseNet"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Quá trình phát triển của CNN từ LeNet đến DenseNet.</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/Sentiment-Analysis-sử-dụng-Tf-Idf"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Sentiment Analysis sử dụng Tf-Idf áp dụng cho ngôn ngữ tiếng việt</div></a></nav></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Thorpham</div></div></div></footer></div>
</body>
</html>