<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.17">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="ThorPham RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="ThorPham Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"><title data-rh="true">Object detection từ R-CNN đến Faster R-CNN | ThorPham</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://thorpham.github.io//blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Object detection từ R-CNN đến Faster R-CNN | ThorPham"><meta data-rh="true" name="description" content="Như chúng ta đã biết object detection bao gồm 2 nhiệm vụ chính là Classifier và Localization. Trong đó nhiệm vụ có vẻ khó khăn hơn là Localization. Trước khi deep learning phát triển như hiện nay, trong computer vision người ta detection object qua 2 giai đoạn. Đầu tiên là trích xuất feature từ hog,lbp,sift sau đó dùng các thuật toán trong machine learning như SVM để classifier. Bước tiếp theo là detection object trên ảnh lớn thì người ta sẽ dùng 1 window search trên toàn bộ bức ảnh sau đó dùng model đã classifier để phân lớp object. Các model này có ưu điểm là thời gian build model tương đối nhanh, cần ít dữ liệu . Nhược điểm là độ chính xác không cao và thời gian predict rất lâu nên khó có thể dùng trong real time."><meta data-rh="true" property="og:description" content="Như chúng ta đã biết object detection bao gồm 2 nhiệm vụ chính là Classifier và Localization. Trong đó nhiệm vụ có vẻ khó khăn hơn là Localization. Trước khi deep learning phát triển như hiện nay, trong computer vision người ta detection object qua 2 giai đoạn. Đầu tiên là trích xuất feature từ hog,lbp,sift sau đó dùng các thuật toán trong machine learning như SVM để classifier. Bước tiếp theo là detection object trên ảnh lớn thì người ta sẽ dùng 1 window search trên toàn bộ bức ảnh sau đó dùng model đã classifier để phân lớp object. Các model này có ưu điểm là thời gian build model tương đối nhanh, cần ít dữ liệu . Nhược điểm là độ chính xác không cao và thời gian predict rất lâu nên khó có thể dùng trong real time."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2018-08-08T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/ThorPham"><meta data-rh="true" property="article:tag" content="Object detection,CNN"><link data-rh="true" rel="icon" href="/img/emoticon_big.png"><link data-rh="true" rel="canonical" href="https://thorpham.github.io//blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN"><link data-rh="true" rel="alternate" href="https://thorpham.github.io//blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN" hreflang="en"><link data-rh="true" rel="alternate" href="https://thorpham.github.io//blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.3d28ff35.css">
<link rel="preload" href="/assets/js/runtime~main.d362079d.js" as="script">
<link rel="preload" href="/assets/js/main.776018b6.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/emoticon_big.png" alt="My Site Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/emoticon_big.png" alt="My Site Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Thorpham</b></a><a class="navbar__item navbar__link" href="/docs/intro">Tutorial</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/Archive">Archive</a><a href="https://github.com/ThorPham" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_S7eR toggle_TdHA toggleDisabled_f9M3"><div class="toggleButton_rCf9" role="button" tabindex="-1"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_v35p"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_nQuB"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></div><input type="checkbox" class="toggleScreenReader_g2nN" aria-label="Switch between dark and light mode (currently light mode)"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/Graph-convolution-network-cho-bài-toán-rút-trích-thông-tin">Hướng tiếp cận Graph convolution network cho bài toán rút trích thông tin từ hóa đơn</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/Quá-trình-phát-triển-của-CNN-từ-LeNet-đến-DenseNet">Quá trình phát triển của CNN từ LeNet đến DenseNet.</a></li><li class="sidebarItem_CF0Q"><a aria-current="page" class="sidebarItemLink_miNk sidebarItemLinkActive_RRTD" href="/blog/Object-detection-từ-R-CNN-đến-Faster-R-CNN">Object detection từ R-CNN đến Faster R-CNN</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/Sentiment-Analysis-sử-dụng-Tf-Idf">Sentiment Analysis sử dụng Tf-Idf áp dụng cho ngôn ngữ tiếng việt</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/Nhận-dạng-chữ-số-viết-tay">Nhận dạng chữ số viết tay với sklearn và opencv</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">Object detection từ R-CNN đến Faster R-CNN</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2018-08-08T00:00:00.000Z" itemprop="datePublished">August 8, 2018</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><span class="avatar__photo-link avatar__photo"><a href="https://github.com/ThorPham" target="_blank" rel="noopener noreferrer"><img class="image_o0gy" src="https://github.com/ThorPham.png" alt="Thorpham"></a></span><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/ThorPham" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Thorpham</span></a></div><small class="avatar__subtitle" itemprop="description">Deep learning enthusiast</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p><em>Như chúng ta đã biết object detection bao gồm 2 nhiệm vụ chính là Classifier và Localization. Trong đó nhiệm vụ có vẻ khó khăn hơn là Localization. Trước khi deep learning phát triển như hiện nay, trong computer vision người ta detection object qua 2 giai đoạn. Đầu tiên là trích xuất feature từ hog,lbp,sift sau đó dùng các thuật toán trong machine learning như SVM để classifier. Bước tiếp theo là detection object trên ảnh lớn thì người ta sẽ dùng 1 window search trên toàn bộ bức ảnh sau đó dùng model đã classifier để phân lớp object. Các model này có ưu điểm là thời gian build model tương đối nhanh, cần ít dữ liệu . Nhược điểm là độ chính xác không cao và thời gian predict rất lâu nên khó có thể dùng trong real time.</em></p><p>Với tộc độ phát triển như hiện nay , dữ liệu của chúng ta ngày càng nhiều và các bài toán bắt đầu khó dần lên nên những model truyền thống tỏ ra kém hiệu quả. Các feature lấy ra từ computer vision truyền thống như hog,sift,lbp là những shadow feature nó chỉ lấy được những feature trên bề mặt nổi image mà thôi, do đó những bài toán như classifer con chó hay con mèo thì những feature này làm việc tương đối hiệu quả , nhưng nâng cấp bài toán lên đó là classifier con bull dog hay con béc rê thì những feature này làm việc kém hiệu quả. Cũng dễ hiểu vì cùng 1 class là dog thì những feature này tương đối giống nhau nên khó có thể phân biệt được con này con kia. Chính vì thế ta cần những feature sâu hơn, những feature mà nó ẩn ở trong image mà ta khó có thể quan sát được bằng mắt thường để phân biệt dog này hay dog kia. Trong deep learning , object detection nền tảng cơ bản là dựa trên mạng CNN để lấy những deep feature bằng cách đưa qua nhiều layer khác nhau feature được extract sâu hơn sau đó được đưa vào classifier và regression box. Hai hướng tiếp cận chính trong deep learning là :</p><ul><li>Chia image ra thành những grid cell SxS . Mỗi cell được coi như region proposal giúp giảm thời gian và chi phí tính toán thay vì sử dụng trực tiếp image ( model SSD,YOLO)</li><li>Tìm những region proposal có nhiều khẳn năng chứa object nhất sử dụng selective search hay RPN ( model R-CNN,Fast R-CNN, Faster R-CNN)</li></ul><p>Trong bài này chúng ta sẽ tìm hiểu về các họ nhà CNN cho object detection.</p><center><img width="600" height="300" src="/assets/images/35474711_223243181605917_1003697740695207936_n-aa4c8770a68789d1549024a2ec3f4950.png"></center><h2 class="anchor anchorWithStickyNavbar_mojV" id="1-r-cnn">1. R-CNN<a class="hash-link" href="#1-r-cnn" title="Direct link to heading">​</a></h2><center><img width="600" height="300" src="/assets/images/35329075_223246958272206_8520772647733166080_n-0008f462f66954c8692ad2fe21121dd2.png"></center><p>R-CNN là viết tắt của “Region-based Convolutional Neural Networks”. Ý tưởng chính của nó gồm 2 phần : Đầu tiên là dùng selective search tìm các region of interest (roi) trên image để tạo ra các bounding box mà có xác suất cao là có object. Sau đó dùng CNN để lấy feature từ các region này để classifier và regression  box. Các bước thực hiện như sau :</p><ul><li>Từ input image ta dùng selective search để lấy cái region proposal .Selective Search nó hoạt động bằng cách là đầu tiên tạo ra các seed là các region segementation trên image(trong skimage họ dùng Felsenszwalb’s efficient graph based image segmentation) Các region sau đó sẽ được merger lại với nhau bằng cách tính độ tương đồng về color,shape,textuture… Cuối cùng ta vẽ bounding box cho từng region.Mỗi image người ta sẽ lấy tầm 2k region proposal.</li><li>Tiếp đến các region proposal sẽ được swarped(crop) để fix size(vì một số mạng như VGG yêu cầu size input là cố định,hơn nữa ta cần feature output same size). Sau đó dùng CNN( VGG,Alexnet) để lấy feature.</li><li>Cuối cùng là dùng SVM để classifier và regression bounding box
Nhược điểm của phương pháp này là training rất lâu vì 2k image qua CNN để lấy feature mất rất nhiều thời gian (52 s trên cpu) . </li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="2-spp-net">2. SPP net<a class="hash-link" href="#2-spp-net" title="Direct link to heading">​</a></h2><center><img width="600" height="300" src="/assets/images/35346991_223247254938843_4269602627899097088_n-1104a3ea805cf4d3708d2aa328e04667.png"></center><p>Thay vì feed forword 2k image qua CNN thì người ta feed forwork qua CNN một lần để lấy feature map (feature map = feature + location). Sau đó dùng selective search để tìm region proposal, rồi project trên feature map để lấy feature tương ứng. Có một vấn đề ở đây là các feature map của region proposal có size khác nhau nên khi đưa qua CNN sẽ có length output khác nhau. Vì vậy người ta sử dụng Spatial paramy pooling layer để  fix size feature.(spp layer hoạt động  cũng tương tự bag of word trong image processing nó sẽ chia feature theo Spatial pyramid và áp dụng max pooling theo từng spatial giúp các feature có size khác nhau thành same size). Phần sau còn lại tương tự như R-CNN</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="3-fast-r-cnn">3. Fast R-CNN<a class="hash-link" href="#3-fast-r-cnn" title="Direct link to heading">​</a></h2><center><img width="600" height="300" src="/assets/images/35348615_223247421605493_4297776049992761344_n-1eb38bea200f935c0b6f9f4ff7dc5ed1.png"></center><p>Fast R-CNN cải thiện được các nhược điểm của R-CNN bằng cách hợp nhất 3 model độc lập vốn rất chậm chạp. Nó cũng có phần giống SPP-net là dùng CNN để lấy feature map một lần thay vì dùng riêng cho mỗi region proposal. Sau đó những feature này sẽ được đưa qua một Fully connection layer để classifier và regression bounding box. Model này tương đối nhanh chạy 2s/image.
Các bước thức hiện thuật toán :</p><ul><li>Dùng pretraining model (VGG,ZF…) để lấy feature map.</li><li>Sử dụng selective search để lấy region proposal (~2k image). Sau đó project lên feature map để lấy feature tương ứng</li><li>Feature sẽ được đưa qua ROI pooling để fix size.</li><li>Cuối cùng Fully connection layer để classifier và regression box</li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="4-faster-r-cnn">4. Faster R-CNN<a class="hash-link" href="#4-faster-r-cnn" title="Direct link to heading">​</a></h2><center><img width="600" height="300" src="/assets/images/35326994_223247604938808_7752372882168086528_n-884aea70061745f6ba6243a5c75ecdb5.png"></center><p>Faster R-CNN gồm region proposal network ( nó thay thế cho selective search) và phần còn lại tương tự như Fast R-CNN. Region proposal network(RPN) nó dùng 1 sliding window search trên feature map để tạo các anchor box. Sau đó chúng ta chuẩn bị data training cho RPN bằng cách gán nhãn cho mỗi anchor box dựa vào iou với ground truth. Cuối cùng dùng data này để classifier và regression bounding box. Ta thu được rất nhiều bounding box và dùng non maximum suppression(NMS) để loại bỏ bớt đi những box không có nhiều khẳn năng chứa object. Sau đó những bounding box này sẽ tương tự như selective search ở fast R-CNN nó được đưa qua ROI pooling để fix size và cuối cùng đưa vào fully connection layer để classifier (xác định object cụ thể) và regression box. Model này tương đối nhanh predict 0.2s/image(gpu)
Model gồm các bước sau :
Pretrain model CNN để lấy feature map.</p><ul><li>Training RPN để tìm bouding box và classifier (chỉ xác định là object và non-object không classifier cụ thể object). Một siliding window size NxM search trên feature map. Tại mỗi center của window, ta predict mutil region với scale và ratio khác nhau. Thông thường là 3 scale và 3 ratio nên tạo ra 9 anchor box. Positive sample IOU &gt; 0.7, negative sample IOU &lt; 0.3.</li><li>Dùng data này training để classifier và regression . Vì số background nhiều nên để hạn chế bias người ta dùng mini bath để training mỗi lần đưa vào tỉ lệ một pos và neg nhất định. Sau đó loại bớt bounding box có ít khẳn năng chứa object bằng NMS.</li><li>Ta project bounding box lên feature map để lấy feature tương ứng sau đó đưa vào ROI pooling layer fix size để đưa vào Fully connection layer để classifier từng object và regression box.</li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="5-kết-luận">5. Kết luận<a class="hash-link" href="#5-kết-luận" title="Direct link to heading">​</a></h2><p>Trên đây mới chỉ là một bài giới thiệu sơ qua về cách hoạt động của R-CNN đến Faster R-CNN. Bên trong cấu trúc của mỗi model này tương đối phức tạp. Nếu có thể mình sẽ viết chi tiết cách hoạt động của từng model qua các bài sau.</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/object-detection">Object detection</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/cnn">CNN</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/ThorPham/blog/2018-8-8-Object-detection-từ-R-CNN-đến-Faster-R-CNN/index.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/Quá-trình-phát-triển-của-CNN-từ-LeNet-đến-DenseNet"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Quá trình phát triển của CNN từ LeNet đến DenseNet.</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/Sentiment-Analysis-sử-dụng-Tf-Idf"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Sentiment Analysis sử dụng Tf-Idf áp dụng cho ngôn ngữ tiếng việt</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-r-cnn" class="table-of-contents__link toc-highlight">1. R-CNN</a></li><li><a href="#2-spp-net" class="table-of-contents__link toc-highlight">2. SPP net</a></li><li><a href="#3-fast-r-cnn" class="table-of-contents__link toc-highlight">3. Fast R-CNN</a></li><li><a href="#4-faster-r-cnn" class="table-of-contents__link toc-highlight">4. Faster R-CNN</a></li><li><a href="#5-kết-luận" class="table-of-contents__link toc-highlight">5. Kết luận</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 Thorpham</div></div></div></footer></div>
<script src="/assets/js/runtime~main.d362079d.js"></script>
<script src="/assets/js/main.776018b6.js"></script>
</body>
</html>